{
  "hash": "9983d67ba52b98de3cb212fee9480e38",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A lesson of advanced python from Juan Rodríguez\"\ndescription: \"The lecture by Juan Luis Cano Rodríguez in Master in Business Analytics and Big Data, 2021-2022, which focused on modern SWE practices using Python and the insight we can gain on how Data Science projects are put into production.\"\nauthor:\n  - name: \"Tuan Le Khac\"\n    url: https://lktuan.github.io/\ncategories: [python, pydata] \ndate: 07-08-2024\ndate-modified: 07-09-2024\nimage: juan_r.png\ncode-tools: true\ncode-fold: show\ncode-annotations: hover\ndraft: false\ncss: html/styles.scss\nfig-cap-location: bottom\neditor: visual\nformat:\n  html:\n    code-overflow: wrap\n---\n\nThis [lesson](https://github.com/astrojuanlu/ie-mbd-advanced-python/tree/main) was found on [Juan Luis Cano Rodríguez's](https://github.com/astrojuanlu) github profile when I came across his talk [\"Building the composable Python data stack with Kedro & Ibis\"](https://www.youtube.com/watch?v=ffDHdtz_vKc) (bookmarked for learning later) in [Pydata London 2024](https://www.youtube.com/playlist?list=PLGVZCDnMOq0rrhYTNedKKuJ9716fEaAdK).\n\nThis is my notes:\n\n# 00 [intro](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/00_intro.ipynb)\n\n## learning objectives\n\n- Learn modern software engineering practices using Python\n- Understand the value of automation in the software engineering process\n- Gain insight into how Data Science projects are put in production\n- Learn better techniques to collaborate in software projects\n\nThe instructor used Linux / Conda, err I just have Window here so there is no other way but right I will try to make stuffs work in Window. Let's get started!\n\n:::{layout-ncol=\"1\"}\n![stolen from the lecture](https://raw.githubusercontent.com/astrojuanlu/ie-mbd-advanced-python/e2224276f91529280ebfcd42ddc7dc22cf0d2010/img/quote-talk-is-cheap-show-me-the-code-linus-torvalds-273528.jpg)\n:::\n\n# 01 [git](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/01_git.ipynb)\n\n## glossary\n\n- **Repository**: Directory tracked by git, contains a `.git` folder and it's created by `$ git init`;\n- **Commit**: State or snapshot of the repository, they are created by `$ git commit`;\n- **Branch**: A parallel or separate line of development, the default one is master and they are created by `$ git branch` or `$ git checkout -b`.\n\n## git uses a Linux-like cli so now Linux cli 101 (and how to do the same on Window pwsh)\n\n- `whoami`: who am i\n- `pwd`: print working directory\n- `ls`: list all file in the dir, `.` for current folder, `..` for parent one (seems there is no `--color` or `-a` in pwsh)\n- `cd`: change dir \n- `touch`: create empty file (in pwsh we use `echo \"\" >> file_name`)\n- `cat`: concatenate, print file contents\n- `nano`: edit a file from the command line (there is a [way](https://www.hanselman.com/blog/developers-can-run-bash-shell-and-usermode-ubuntu-linux-binaries-on-windows-10) that allows us to do the same in win10, but ya, nope)\n\n## workflow\n\nI did these in pwsh:\n\n1. Create a directory `mkdir test_project` and navigate there `cd test_project`;\n2. Init a git repository `git init`;\n3. Check status `git status` (\"on branch master, no commits yet, nothing to commit\");\n4. Create some files `echo \"#Hello, world!\" >> readme.md`;\n5. Stage the files `git add readme.md`;\n6. Commit the changes `git commit -m \"initial commit\"`;\n\n:::{.callout-warning}\nDo not run `git init` on your home directory, as it can lead to confusion and potential data loss. If `git status` gives a lot of untracked files unrelated to your project, you might want to `rm -rf .git` and start in another directory. Notice that this command removes all git history.\n:::\n\n## branching\n\n1. Create and checkout to new branch `git switch -c branch1` (`-c` stands for create); \n2. Commit there (see above);\n3. Go back to main branch `git switch master`;\n6. Merge changes `git merge branch1`;\n5. Delete branch `git branch -d branch1` (`-d` stands for delete, don't forget this step!).\n\n:::{.callout-tip}\n- Normally, the `git merge` step happens online using *pull requests* or *merge requests*, which are **not** git concepts, but GitHub/GitLab concepts.\n- If `git switch` does not work for you, you might have an older version of Git. Consider upgrading, or alternatively replace all `git switch -c` with `git checkout -b`.\n:::\n\n> Pull requests (PR) let you tell others about changes you've pushed to a branch in a repository on GitHub. Once a pull request is opened, you can discuss and review the potential changes with collaborators and add follow-up commits before your changes are merged into the base branch. -- GitHub\n\n> A merge request (MR) is a proposal to incorporate changes from a source branch to a target branch. -- GitLab\n\n> Remember to **never commit to master**. -- Git Workflow\n\n## merging\n\n2 types of merging:\n\n- **Fast-forward merge**: There is no diverging history, and git just \"advances the pointer\" of the current branch. `git merge new-branch --ff-only` will fail if a fast-forward merge is not possible;\n- **Non fast-forward merge**: The history diverged, and git will create a merge commit (hence ask for a commit message) with two parents that combines the two branches. `git merge new-branch --no-ff` always creates a merge commit even if a fast-forward merge is possible.\n\nGitHub use `--no--ff` option for pull requests, see [here](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/incorporating-changes-from-a-pull-request/merging-a-pull-request), and this old-but-gold [discussion](https://stackoverflow.com/questions/9069061/what-effect-does-the-no-ff-flag-have-for-git-merge).\n\n- Non fast-forward merges can end up in conflicts. In that case, git will halt the merge operation and leave traces in the affected files;\n- To abort a merge `git merge --abort` (useful if we are scared and don't know what to do);\n- To merge overriding everything with the upcoming branch `git merge new-branch --strategy-option theirs`;\n- To merge overriding everything with the current branch `git merge new-branch --strategy-option ours`.\n\n**Be careful** while editing files that are in conflict.\n\n## other\n\n- Ignoring files `.gitignore`;\n- Amend the last commit: `git commit --amend`;\n- Show pretty history: `git log --graph --oneline --decorate --all`;\n- Configuring git aliases: `git config --global alias.lg \"log --graph --oneline --decorate\"` (and now you have `git lg`!).\n\nThis excellent chart will help you in git workflow decision making.\n\n:::{layout-ncol=\"1\"}\n![git flowchart, photo credit to this SO [thread](https://stackoverflow.com/questions/14096721/how-to-add-file-to-a-previous-commit)](git_pretty.png)\n:::\n\n## triangular workflows in git\n\nWhen collaborating with a project hosted online on GitHub or GitLab, the most common setup is having a central repository, one remote fork per user, and local clones/checkouts:\n\n:::{layout-ncol=\"1\"}\n![triangular workflows in git, [source](https://github.blog/2015-07-29-git-2-5-including-multiple-worktrees-and-triangular-workflows/)](https://github.blog/wp-content/uploads/2015/07/5dcdcae4-354a-11e5-9f82-915914fad4f7.png?resize=2000%2C951)\n:::\n\nNotice the different naming conventions between this website and the first image:\n\n- Convention 1: upstream/origin/local\n- Convention 2: origin/<username>/local\n\nWe will be consistent with the Aaron Meurer guide and therefore use Convention 2 all the time.\n\n## after creating a PR\n\nAfter your pull request has been merged to `master`, your local `master` and `<username>/master` will be outdated with respect to `origin/master`. On the other hand, you should **avoid working on this branch anymore in the future**: remember branches should be ephemeral and short-lived.\n\nTo put yourself in a clean state again, you have to:\n\n1. Click \"remove branch\" in the pull request (don't click \"remove fork\"!);\n2. `git checkout master` (go back to master);\n3. `git fetch origin` (**never, ever** use `git pull` unless you know exactly what you're doing)\n4. `git merge --ff-only origin master` (update your local master with origin/master, and fail if you accidentally made any commit in master)\n5. `git fetch -p <username>` (✨ acknowledge the removal of the remote branch ✨)\n6. `git branch -d old-branch` (remove the old branch)\n7. `git push <username> master` (update your fork with respect to origin)\n8. `git checkout -b new-branch` (start working in the new feature!)\n\nThis process has to be repeated **after every pull request**.\n\nSome organizations where all the members are trusted do not use forks, and everybody pushes their branches to the same repository instead. While this simplifies some parts of the workflow, it also requires proper checks in place to prevent bad code to be merged - for example, by [requiring a minimum number of reviews](https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/managing-protected-branches/managing-a-branch-protection-rule) or some [automated status checks](https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/managing-protected-branches/about-protected-branches).\n\n# 02 [pythonpath](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/02_pythonpath.ipynb)\n\n## how does `import` work?\n\nHow do `import os, pandas` work? If `pandas` was not installed, what happen?\n\n## how can I `import` my code?\n\nThere are three ways to import our own code:\n\n- **Being on the same directory**: This is the quickest, however it scales quite poorly (imagine having all of pandas and scikit-learn in a single directory to do any data analysis project!)\n- **Appending our code location to PYTHONPATH**: This is effective, but we will try to avoid it because it can bring problems in the future.\n- **Making our code installable**: Since any code that's installed can be imported, this shifts the question to \"how to make our code installable\".\n\n## my first python lib\n\nWe will create a new Python library, \"IE Titanic utils\", to analyze the [Titanic dataset](https://www.kaggle.com/c/titanic/data). I will create a project `ie-titanic-utils`, add `readme.md` and `.gitignore` files.\n\n```bash\nmkdir it-titanic-utils\ngit init\n\necho \"# This is utility to help analyze Titanic dataset\" >> readme.md\nInvoke-WebRequest -Uri \"https://www.toptal.com/developers/gitignore/api/python,jupyternotebooks\" | Select-Object -ExpandProperty Content | Out-File -FilePath .gitignore -Encoding utf8\n\ngit add readme.md .gitignore\ngit commit -m \"initial commit\"\n```\n\nNow I will create `str_utils.py` file (using VS code for convenience), with a function called `tokenize` that takes a str sentence and splits it into a list of words.\n\n```{.python filename=\"str_utils.py\"}\ndef tokenize(sentence: str) -> list[str]:\n    return sentence.split()\n\n```\n\nIn pwsh, I can import and use this function\n\n```bash\npython\nPython 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> from str_utils import tokenize\n>>> tokenize(\"Toi la Le Khac Tuan\")\n['Toi', 'la', 'Le', 'Khac', 'Tuan']\n>>>\n```\n\n## the `PYTHONPATH`\n\nWe saw above that we could easily import our `tokenize` function. However, this only works if we are in the same directory. Why? Python looks in some predefined locations to know where to find what we want to import, called the \"PATH\".\n\n::: {#3a236e54 .cell execution_count=1}\n``` {.python .cell-code}\nimport sys\nsys.path # i will not execute this code\n```\n:::\n\n\nTherefore, there are two ways of making our code **globally importable**:\n\n1. Modify the \"PATH\"\n2. Put our code inside a location predefined in the \"PATH\"\n\nThe first option can be achieved like this:\n\n::: {#6c38e56d .cell execution_count=2}\n``` {.python .cell-code}\n>>> sys.path.insert(0, \"/home/username/ie-titanic-utils\")\n>>> import str_utils  # Works!\n```\n:::\n\n\nOr, alternatively, from outside of the interpreter: `export PYTHONPATH=/home/username/ie-titanic-utils`.\n\nHowever, both are **bad practices and should be avoided**.\n\n## what does `import` do?\n\nPython code is normally written in `.py` scripts. These scripts can be imported in the same way that any model or package from the standard library can:\n\n```bash\n$ python3\n>>> import math  # Works, because it's in stdlib\n>>> import numpy as np  # Works if you ran `pip install numpy` in advance\n>>> import str_utils  # Works if you are in the same directory\n['Hello,', 'world!']\n>>> \n```\n\nWhen the user imports a script, **Python runs the script**. That's the way all the possible functions and classes inside it are available.\n\n## how to separate \"running code\" from reusable pieces\n\nA Python module (any `.py` script) might contain code that we want to run, as well as code that we only want to import. To separate these, we use this trick:\n\n```bash\n ie-titanic-utils  get-content -Tail 2 .str_utils.py\nif __name__ == \"__main__\":\n    print(tokenize(\"hello, world!\"))\n\n ie-titanic-utils  python .str_utils.py # The `print` runs\n['hello,', 'world!']\n\n ie-titanic-utils  python\n>>> from str_utils import tokenize\n>>> tokenize(\"Hi, world!\")\n['Hi,', 'world!'] # The `print` doesn't run!\n>>>\n```\n\n:::{.callout-tip}\nHere is what Claude sonnet 3.5 gave me:\n\nTo separate code that we want to run directly from code that we only want to import, we should use the if `__name__ == \"__main__\"`: idiom in Python. This is a common pattern that allows a Python script to be both importable and executable. Here's an explanation:\n\n1. When a Python file is run directly, Python sets the special `__name__` variable to \"`__main__`\".\n2. When a Python file is imported as a module,` __name__ `is set to the name of the module.\n\nBy using this idiom, we can control which code runs when the script is executed directly versus when it's imported as a module.\n:::\n\n# 03&04 [pip vs. conda](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/03-04_pip-vs-conda.ipynb)\n\n## managing python environments\n\n:::{layout-ncol=\"1\"}\n![stolen from the lecture](https://raw.githubusercontent.com/astrojuanlu/ie-mbd-advanced-python/e2224276f91529280ebfcd42ddc7dc22cf0d2010/img/python_comrades.png)\n:::\n\n> Simple is better than complex.\n> \n> Complex is better than complicated.\n\nHow do people install and upgrade Python? -> Most of people choose Python.org, the same for me!\n\n:::{.callout-caution}\nThis way ships a tool to create development environments (`venv`). However, `venv` cannot create environments with different Python versions (you're tied to the one you downloaded) and certain packages will require extra steps to be installed. Therefore, it **is not** for everyone.\n:::\n\nJuan chose to use `conda`. As I am learning Docker, I choose Docker for this tutorial.\n\nHow do people create isolated development environments? -> The most popular is `Virtualenv`. But normally when doing an analysis task, I use `venv` which is built-in python lib. Recently I followed my dev team to use `pipenv`, I do also see `poetry` is worth-learning approach.\n\n> \"More than a half of the users of Jupyter Notebook and JupyterLab choose Conda\"\n\nAs I think a model which is not deployed yet is useless model, I choose VS Code and Docker - more deployment-oriented. \n\n## summary\n\n> For the user, the most salient distinction is probably this: pip installs python packages within any environment; conda installs any package within conda environments.\n> \n> —Jake Vanderplas\n\nHowever, I will be using `pipenv` to achieve what Juan done in upcoming sections. I will specify version of each package I used.\n\n## `pip` and `PyPI`\n\n`pip` is the default Python installer. By default, it fetches packages from <https://pypi.org/>, which is the community repository for Python packages.\n\n# 05 layout\n\nhere is my project's layout:\n\n```bash\nie-titanic-utils\n├─ src\n│  └─ ie_titanic_utils\n│     ├─ __init__.py\n│     └─ ...\n├─ tests\n│  └─ ...\n├─ .gitignore\n├─ README.md\n└─ pyproject.toml\n```\n\n- The `src/package_name` contains the source code of the library. `package_name` must be Python identifier. It should contain a `__init__.py` that can be empty;\n- The `tests` directory contains the tests. It must not contain any `__init__.py` because it's not meant to be imported as a package. In very specific cases it's included inside `src/package_name`;\n- Every project contains a `README.md` that at least explains what the project is;\n- `pyproject.toml` contains the metadata of the project. The absolutely required fields are `module`, `author`, and some extra information that tells Python how to install the package.\n\n## creating a package\n\n1. run `flit init` to create the metadata\n\n```bash\n ie-titanic-utils  flit init\npyproject.toml exists - overwrite it? [y/N]: y\nModule name [ie_titanic_utils]: ie_utils\nAuthor: Tuan Le Khac\nAuthor email: tuan.lekhac0905@gmail.com\nHome page: \nChoose a license (see http://choosealicense.com/ for more info)\n1. MIT - simple and permissive\n2. Apache - explicitly grants patent rights\n3. GPL - ensures that code based on this is shared with the same terms\n4. Skip - choose a license later\nEnter 1-4: 4\n\nWritten pyproject.toml; edit that file to add optional extra info.\n```\n\n2. place some code under the source directory. In `__init__.py` there must be a docstring giving a description of the project and a `__version__` variable indicating the version:\n\n```{.python filename=\"__init__.py\"}\n\"\"\"IE utils (test package).\"\"\"\n\n__version__ = \"0.1.0\"\n```\n\n3. Install the code using `pip install`! (this did not work for me currently. edit: the project name should match the `src/package_name` omg)\n\n```bash\n ie-titanic-utils  pip install .\nProcessing .ie-titanic-utils\n...\nSuccessfully installed ie_titanic_utils-0.1.0\n ie-titanic-utils  python\nPython 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import ie_titanic_utils\n>>> ie_titanic_utils.__version__\n'0.1.0'\n>>>    \n```\n\n4. `readme.md` and a `.gitignore` files were created.\n5. commit the change\n\n```bash\ngit checkout -b first_module # i should be using switch (-c) haha, checkout is old syntax\ngit status\ngit add .\ngit commit -m \"initial very first module\"\ngit checkout master\n\n ie-titanic-utils  git merge --no-ff first_module\nMerge made by the 'ort' strategy.\n pyproject.toml                    | 30 ++++++++++++++++++++++++++++++\n src/ie_titanic_utils/__init__.py  |  6 ++++++\n src/ie_titanic_utils/str_utils.py |  6 ++++++\n 3 files changed, 42 insertions(+)\n create mode 100644 pyproject.toml\n create mode 100644 src/ie_titanic_utils/__init__.py\n create mode 100644 src/ie_titanic_utils/str_utils.py\n\ngit branch -d first_module\n# git push origin master\n# as I will not upload this code to GitHub\n# https://stackoverflow.com/questions/32238616/git-push-fatal-origin-does-not-appear-to-be-a-git-repository-fatal-could-n\n```\n\nNow if I log the git, I will see this:\n\n```bash\n ie-titanic-utils  git log --graph --oneline --decorate --all\n*   39105c7 (HEAD -> master) Merge branch 'first_module'\n|\n| * 7a33844 initial very first module\n|/\n* 793bd67 initial commit\n```\n\nYeah til now I can create a \"package\" in my computer and install so I can use it **globally**. But I have not use any env management yet.\n\n## intermezzo: version numbers\n\n+ Version numbers for Python packages are explained in [PEP 440](https://www.python.org/dev/peps/pep-0440/)\n+ For libraries, the most widely used convention is [semantic versioning](https://semver.org/): X.Y.Z\n  - Z **must** be incremented if only backwards compatible bug fixes are introduced (a bug fix is defined as an internal change that fixes incorrect behavior)\n  - Y **must** be incremented every time there is new, backwards-compatible functionality\n  - X **must** be incremented every time there are backwards-incompatible changes\n+ Between releases, the version should have the `.dev0` suffix\n+ Recommendation: start with 0.1.dev0 (development version), then make a `0.1.0` release, then progress to `0.1.1` for quick fixes and `0.2.0` for new functionality, and when you want to make a promise of relative stability jump to `1.0.0`.\n+ For applications, other conventions are more appropriate, like [calendar versioning](https://calver.org/): `[YY]YY.MM.??`\n\n## project requirements\n\nSometimes our project will depend on third-party libraries (pandas, scikit-learn). To make pip install those dependencies automatically, we can add them to our `pyproject.toml` under the `[tool.flit.metadata]` section, using the `requires` option:\n\n```md\n[build-system]\nrequires = [\"flit_core>=3.4\"]\nbuild-backend = \"flit_core.buildapi\"\n\n[project]\nname = \"ie_titanic_utils\"\nauthors = [{name = \"Tuan Le Khac\", email = \"tuan.lekhac0905@gmail.com\"}]\nreadme = \"readme.md\"\nrequires-python = \">=3.11\"\ndynamic = [\"version\", \"description\"]\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\nrequires = [\n    \"pandas\",\n    \"matplotlib>=2\",\n]\n```\n\nWe might want to specify *optional* dependencies that should only be installed upon request, or for some specific purposes. A typical example will be development dependencies: we will need things like `pytest` and `black`, but we don't want the user to install them as part as our library. To do that, we can specify *groups* of optional dependencies under the `tool.flit.metadata.requires-extra` section:\n\n```md\nIn my case, I use `project.optional-dependencies`: flit_core.config.ConfigError: Use [project] table for metadata or [tool.flit.metadata], not both.\n[project.optional-dependencies]\ndev = [\n    \"pytest>=6.0\",\n    \"black>=20.8b1\",\n]\n```\n\nThat way, they will only get installed when `[dev]` is added after the name of our library:\n\n```bash\n ie-titanic-utils  pip install .[dev]\n# Successfully installed black-24.4.2 ie_titanic_utils-0.1.0 iniconfig-2.0.0 pytest-8.2.2\n```\n\n# 06 [unit test](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/06_unit-tests.ipynb)\n\n> If you use software that lacks automated tests, you are the tests.\n> \n> — Jenny Bryan (@JennyBryan) [September 22, 2018](https://x.com/JennyBryan/status/1043307291909316609?ref_src=twsrc%5Etfw)\n\nTesting is **essential**. Computers excel at doing repetitive tasks: they basically never make mistakes (the mistake might be in what we told the computer to do). Humans, on the other hand, fail more often, especially under pressure, or on Friday afternoons and Monday mornings. Therefore, instead of letting the humans be the tests, we will use the computer to **frequently verify that our software works as specified**.\n\nI will be using `pytest` to achieve this.\n\n## test-driven development\n\nThe \"test-driven development mantra\" is <span style=\"color:red;font-weight:bold;\">Red</span> - <span style=\"color:green;font-weight:bold;\">Green</span> - <span style=\"color:grey;font-weight:bold;\">Refactor</span>:\n\n:::{layout-ncol=\"1\"}\n![Make it work. Make it right. Make it fast.](https://raw.githubusercontent.com/astrojuanlu/ie-mbd-advanced-python/e2224276f91529280ebfcd42ddc7dc22cf0d2010/img/red-green-refactor.png)\n:::\n\n1. Write a test. <span style=\"color:red;font-weight:bold;\">Watch it fail</span>.\n2. Write just enough code to <span style=\"color:green;font-weight:bold;\">pass the test</span>.\n3. Improve the code without breaking the test.\n\nRepeat.\n\n## testing in Python\n\nSummary: use `pytest`. Everybody does. It rocks.\n\n[pytest](https://docs.pytest.org/en/8.2.x/) is a testing framework for Python that makes writing tests extremely easy. It is much more powerful than the standard library equivalent, `unittest`. We can use by install it first `pip install pytest`.\n\nWe can write a function that test the `tokenize` funtion:\n\n```{.python filename=\"tests/test_tokenize.py\"}\nfrom ie_titanic_utils import tokenize  # This will fail right away!\n\n\ndef test_tokenize_returns_expected_list():\n    sentence = \"This is a sentence\"\n    expected_tokens = [\"This\", \"is\", \"a\", \"sentence\"]\n\n    tokens = tokenize(sentence)\n\n    assert tokens == expected_tokens\n```\n\nand we run it from the command line:\n\n```bash\n ie-titanic-utils  pytest\n============================================================================================ test session starts ============================================================================================\nplatform win32 -- Python 3.11.4, pytest-8.2.2, pluggy-1.5.0\nrootdir: .ie-titanic-utils\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, time-machine-2.14.0\ncollected 1 item\n\nteststest_tokenize.py .                                                                                                                                                                               [100%] \n\n============================================================================================= 1 passed in 0.02s ============================================================================================= \n```\n\nThe test successed after I fixed the `__init__.py`:\n\n```{.python filename=\"src/./__init__.py\"}\nfrom ie_titanic_utils.str_utils import tokenize\n__all__ = [\"tokenize\"]\n```\n\n# 07&08 [oop](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/07-08_object-oriented-programming.ipynb)\n\n## what are \"objects\" anyway?\n## classes and instances\n## \n# 09&10 [flask](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/09-10_flask.ipynb)\n\n# [conclusion](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/99_conclusion.ipynb)\n\n## where do we go from here\n\n- Keep improving the art of Python packaging\n- Explore other options for high performance Python\n- Help \"bridging the gap\"\n- Engage with the (open source) Python community\n\n## keep improving the art of python packaging\n\n- recommend: `pip-tools` + `requirements.in` = `requirements.txt`\n- Poetry, Pipenv... Yes, they work, but they are way more complex and have \"lock-in\"\n- All companies I worked for struggle sooner or later with their code deployment practices. Now, you know better\n\n## explore other options for high performance python\n\n- Juan mentioned: Numba, Modin, Vaex, Dask, Spark, Coiled, Prefect\n- Now we have more: polar, pandas 2.0, aiflow, dagster, dbt, etc  \n\n:::{layout-ncol=\"1\"}\n![stolen from the lecture](setup_py_br.png)\n:::\n\n# other resources\n\n1. [NBViewer](https://nbviewer.org/github/astrojuanlu/ie-mbd-advanced-python/tree/main/) for this lecture;\n2. [PyData](https://pydata.org/), a community for developers and users of open source data tools;\n3. [Pro Git](https://git-scm.com/book/en/v2/), `--distributed-is-the-new-centralized`;\n4. [Pull Requests](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests);\n5. [Merge Requests](https://docs.gitlab.com/ee/user/project/merge_requests/index.html);\n6. [Git Workflow](https://www.asmeurer.com/git-workflow/), the git workflow for contributing to open source repositories;\n7. [Git Ignore](https://www.toptal.com/developers/gitignore) builder;\n8. [Git commit --amend](https://www.atlassian.com/git/tutorials/rewriting-history), rewriting history;\n9. [The right way to distribute Python code](https://packaging.python.org/en/latest/tutorials/packaging-projects/)\n10. [Python packaging](https://docs.python.org/3/tutorial/modules.html#packages)\n11. [Pytest](https://docs.pytest.org/en/8.2.x/);\n12. \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}