{
  "hash": "712d7f41a9853b6647d7b628f57b1e47",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"A lesson of advanced python from Juan Rodríguez\"\ndescription: \"The lecture by Juan Luis Cano Rodríguez in Master in Business Analytics and Big Data, 2021-2022, which focused on modern SWE practices using Python and the insight we can gain on how Data Science projects are put into production.\"\nauthor:\n  - name: \"Tuan Le Khac\"\n    url: https://lktuan.github.io/\ncategories: [python, pydata] \ndate: 07-08-2024\ndate-modified: 08-01-2024\nimage: juan_r.png\ncode-tools: true\ncode-fold: show\ncode-annotations: hover\ndraft: false\ncss: html/styles.scss\nfig-cap-location: bottom\neditor: visual\nformat:\n  html:\n    code-overflow: wrap\n---\n\nThis [lesson](https://github.com/astrojuanlu/ie-mbd-advanced-python/tree/main) was found on [Juan Luis Cano Rodríguez's](https://github.com/astrojuanlu) github profile when I came across his talk [\"Building the composable Python data stack with Kedro & Ibis\"](https://www.youtube.com/watch?v=ffDHdtz_vKc) (bookmarked for learning later) in [Pydata London 2024](https://www.youtube.com/playlist?list=PLGVZCDnMOq0rrhYTNedKKuJ9716fEaAdK).\n\nThis is my notes:\n\n# 00 [intro](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/00_intro.ipynb)\n\n## learning objectives\n\n- Learn modern software engineering practices using Python\n- Understand the value of automation in the software engineering process\n- Gain insight into how Data Science projects are put in production\n- Learn better techniques to collaborate in software projects\n\nThe instructor used Linux / Conda, err I just have Window here so there is no other way but right I will try to make stuffs work in Window. Let's get started!\n\n:::{layout-ncol=\"1\"}\n![stolen from the lecture](https://raw.githubusercontent.com/astrojuanlu/ie-mbd-advanced-python/e2224276f91529280ebfcd42ddc7dc22cf0d2010/img/quote-talk-is-cheap-show-me-the-code-linus-torvalds-273528.jpg)\n:::\n\n# 01 [git](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/01_git.ipynb)\n\n## glossary\n\n- **Repository**: Directory tracked by git, contains a `.git` folder and it's created by `$ git init`;\n- **Commit**: State or snapshot of the repository, they are created by `$ git commit`;\n- **Branch**: A parallel or separate line of development, the default one is master and they are created by `$ git branch` or `$ git checkout -b`.\n\n## git uses a Linux-like cli so now Linux cli 101 (and how to do the same on Window pwsh)\n\n- `whoami`: who am i\n- `pwd`: print working directory\n- `ls`: list all file in the dir, `.` for current folder, `..` for parent one (seems there is no `--color` or `-a` in pwsh)\n- `cd`: change dir \n- `touch`: create empty file (in pwsh we use `echo \"\" >> file_name`)\n- `cat`: concatenate, print file contents\n- `nano`: edit a file from the command line (there is a [way](https://www.hanselman.com/blog/developers-can-run-bash-shell-and-usermode-ubuntu-linux-binaries-on-windows-10) that allows us to do the same in win10, but ya, nope)\n\n## workflow\n\nI did these in pwsh:\n\n1. Create a directory `mkdir test_project` and navigate there `cd test_project`;\n2. Init a git repository `git init`;\n3. Check status `git status` (\"on branch master, no commits yet, nothing to commit\");\n4. Create some files `echo \"#Hello, world!\" >> readme.md`;\n5. Stage the files `git add readme.md`;\n6. Commit the changes `git commit -m \"initial commit\"`;\n\n:::{.callout-warning}\nDo not run `git init` on your home directory, as it can lead to confusion and potential data loss. If `git status` gives a lot of untracked files unrelated to your project, you might want to `rm -rf .git` and start in another directory. Notice that this command removes all git history.\n:::\n\n## branching\n\n1. Create and checkout to new branch `git switch -c branch1` (`-c` stands for create); \n2. Commit there (see above);\n3. Go back to main branch `git switch master`;\n6. Merge changes `git merge branch1`;\n5. Delete branch `git branch -d branch1` (`-d` stands for delete, don't forget this step!).\n\n:::{.callout-tip}\n- Normally, the `git merge` step happens online using *pull requests* or *merge requests*, which are **not** git concepts, but GitHub/GitLab concepts.\n- If `git switch` does not work for you, you might have an older version of Git. Consider upgrading, or alternatively replace all `git switch -c` with `git checkout -b`.\n:::\n\n> Pull requests (PR) let you tell others about changes you've pushed to a branch in a repository on GitHub. Once a pull request is opened, you can discuss and review the potential changes with collaborators and add follow-up commits before your changes are merged into the base branch. -- GitHub\n\n> A merge request (MR) is a proposal to incorporate changes from a source branch to a target branch. -- GitLab\n\n> Remember to **never commit to master**. -- Git Workflow\n\n## merging\n\n2 types of merging:\n\n- **Fast-forward merge**: There is no diverging history, and git just \"advances the pointer\" of the current branch. `git merge new-branch --ff-only` will fail if a fast-forward merge is not possible;\n- **Non fast-forward merge**: The history diverged, and git will create a merge commit (hence ask for a commit message) with two parents that combines the two branches. `git merge new-branch --no-ff` always creates a merge commit even if a fast-forward merge is possible.\n\nGitHub use `--no--ff` option for pull requests, see [here](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/incorporating-changes-from-a-pull-request/merging-a-pull-request), and this old-but-gold [discussion](https://stackoverflow.com/questions/9069061/what-effect-does-the-no-ff-flag-have-for-git-merge).\n\n- Non fast-forward merges can end up in conflicts. In that case, git will halt the merge operation and leave traces in the affected files;\n- To abort a merge `git merge --abort` (useful if we are scared and don't know what to do);\n- To merge overriding everything with the upcoming branch `git merge new-branch --strategy-option theirs`;\n- To merge overriding everything with the current branch `git merge new-branch --strategy-option ours`.\n\n**Be careful** while editing files that are in conflict.\n\n## other\n\n- Ignoring files `.gitignore`;\n- Amend the last commit: `git commit --amend`;\n- Show pretty history: `git log --graph --oneline --decorate --all`;\n- Configuring git aliases: `git config --global alias.lg \"log --graph --oneline --decorate\"` (and now you have `git lg`!).\n\nThis excellent chart will help you in git workflow decision making.\n\n:::{layout-ncol=\"1\"}\n![git flowchart, photo credit to this SO [thread](https://stackoverflow.com/questions/14096721/how-to-add-file-to-a-previous-commit)](git_pretty.png)\n:::\n\n## triangular workflows in git\n\nWhen collaborating with a project hosted online on GitHub or GitLab, the most common setup is having a central repository, one remote fork per user, and local clones/checkouts:\n\n:::{layout-ncol=\"1\"}\n![triangular workflows in git, [source](https://github.blog/2015-07-29-git-2-5-including-multiple-worktrees-and-triangular-workflows/)](https://github.blog/wp-content/uploads/2015/07/5dcdcae4-354a-11e5-9f82-915914fad4f7.png?resize=2000%2C951)\n:::\n\nNotice the different naming conventions between this website and the first image:\n\n- Convention 1: upstream/origin/local\n- Convention 2: origin/<username>/local\n\nWe will be consistent with the Aaron Meurer guide and therefore use Convention 2 all the time.\n\n## after creating a PR\n\nAfter your pull request has been merged to `master`, your local `master` and `<username>/master` will be outdated with respect to `origin/master`. On the other hand, you should **avoid working on this branch anymore in the future**: remember branches should be ephemeral and short-lived.\n\nTo put yourself in a clean state again, you have to:\n\n1. Click \"remove branch\" in the pull request (don't click \"remove fork\"!);\n2. `git checkout master` (go back to master);\n3. `git fetch origin` (**never, ever** use `git pull` unless you know exactly what you're doing)\n4. `git merge --ff-only origin master` (update your local master with origin/master, and fail if you accidentally made any commit in master)\n5. `git fetch -p <username>` (✨ acknowledge the removal of the remote branch ✨)\n6. `git branch -d old-branch` (remove the old branch)\n7. `git push <username> master` (update your fork with respect to origin)\n8. `git checkout -b new-branch` (start working in the new feature!)\n\nThis process has to be repeated **after every pull request**.\n\nSome organizations where all the members are trusted do not use forks, and everybody pushes their branches to the same repository instead. While this simplifies some parts of the workflow, it also requires proper checks in place to prevent bad code to be merged - for example, by [requiring a minimum number of reviews](https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/managing-protected-branches/managing-a-branch-protection-rule) or some [automated status checks](https://docs.github.com/en/repositories/configuring-branches-and-merges-in-your-repository/managing-protected-branches/about-protected-branches).\n\n# 02 [pythonpath](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/02_pythonpath.ipynb)\n\n## how does `import` work?\n\nHow do `import os, pandas` work? If `pandas` was not installed, what happen?\n\n## how can I `import` my code?\n\nThere are three ways to import our own code:\n\n- **Being on the same directory**: This is the quickest, however it scales quite poorly (imagine having all of pandas and scikit-learn in a single directory to do any data analysis project!)\n- **Appending our code location to PYTHONPATH**: This is effective, but we will try to avoid it because it can bring problems in the future.\n- **Making our code installable**: Since any code that's installed can be imported, this shifts the question to \"how to make our code installable\".\n\n## my first python lib\n\nWe will create a new Python library, \"IE Titanic utils\", to analyze the [Titanic dataset](https://www.kaggle.com/c/titanic/data). I will create a project `ie-titanic-utils`, add `readme.md` and `.gitignore` files.\n\n```bash\nmkdir it-titanic-utils\ngit init\n\necho \"# This is utility to help analyze Titanic dataset\" >> readme.md\nInvoke-WebRequest -Uri \"https://www.toptal.com/developers/gitignore/api/python,jupyternotebooks\" | Select-Object -ExpandProperty Content | Out-File -FilePath .gitignore -Encoding utf8\n\ngit add readme.md .gitignore\ngit commit -m \"initial commit\"\n```\n\nNow I will create `str_utils.py` file (using VS code for convenience), with a function called `tokenize` that takes a str sentence and splits it into a list of words.\n\n```{.python filename=\"str_utils.py\"}\ndef tokenize(sentence: str) -> list[str]:\n    return sentence.split()\n\n```\n\nIn pwsh, I can import and use this function\n\n```bash\npython\nPython 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> from str_utils import tokenize\n>>> tokenize(\"Toi la Le Khac Tuan\")\n['Toi', 'la', 'Le', 'Khac', 'Tuan']\n>>>\n```\n\n## the `PYTHONPATH`\n\nWe saw above that we could easily import our `tokenize` function. However, this only works if we are in the same directory. Why? Python looks in some predefined locations to know where to find what we want to import, called the \"PATH\".\n\n::: {#e4b08fa3 .cell execution_count=1}\n``` {.python .cell-code}\nimport sys\nsys.path # i will not execute this code\n```\n:::\n\n\nTherefore, there are two ways of making our code **globally importable**:\n\n1. Modify the \"PATH\"\n2. Put our code inside a location predefined in the \"PATH\"\n\nThe first option can be achieved like this:\n\n::: {#d729e316 .cell execution_count=2}\n``` {.python .cell-code}\n>>> sys.path.insert(0, \"/home/username/ie-titanic-utils\")\n>>> import str_utils  # Works!\n```\n:::\n\n\nOr, alternatively, from outside of the interpreter: `export PYTHONPATH=/home/username/ie-titanic-utils`.\n\nHowever, both are **bad practices and should be avoided**.\n\n## what does `import` do?\n\nPython code is normally written in `.py` scripts. These scripts can be imported in the same way that any model or package from the standard library can:\n\n```bash\n$ python3\n>>> import math  # Works, because it's in stdlib\n>>> import numpy as np  # Works if you ran `pip install numpy` in advance\n>>> import str_utils  # Works if you are in the same directory\n['Hello,', 'world!']\n>>> \n```\n\nWhen the user imports a script, **Python runs the script**. That's the way all the possible functions and classes inside it are available.\n\n## how to separate \"running code\" from reusable pieces\n\nA Python module (any `.py` script) might contain code that we want to run, as well as code that we only want to import. To separate these, we use this trick:\n\n```bash\n ie-titanic-utils  get-content -Tail 2 .str_utils.py\nif __name__ == \"__main__\":\n    print(tokenize(\"hello, world!\"))\n\n ie-titanic-utils  python .str_utils.py # The `print` runs\n['hello,', 'world!']\n\n ie-titanic-utils  python\n>>> from str_utils import tokenize\n>>> tokenize(\"Hi, world!\")\n['Hi,', 'world!'] # The `print` doesn't run!\n>>>\n```\n\n:::{.callout-tip}\nHere is what Claude sonnet 3.5 gave me:\n\nTo separate code that we want to run directly from code that we only want to import, we should use the if `__name__ == \"__main__\"`: idiom in Python. This is a common pattern that allows a Python script to be both importable and executable. Here's an explanation:\n\n1. When a Python file is run directly, Python sets the special `__name__` variable to \"`__main__`\".\n2. When a Python file is imported as a module,` __name__ `is set to the name of the module.\n\nBy using this idiom, we can control which code runs when the script is executed directly versus when it's imported as a module.\n:::\n\n# 03&04 [pip vs. conda](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/03-04_pip-vs-conda.ipynb)\n\n## managing python environments\n\n:::{layout-ncol=\"1\"}\n![stolen from the lecture](https://raw.githubusercontent.com/astrojuanlu/ie-mbd-advanced-python/e2224276f91529280ebfcd42ddc7dc22cf0d2010/img/python_comrades.png)\n:::\n\n> Simple is better than complex.\n> \n> Complex is better than complicated.\n\nHow do people install and upgrade Python? -> Most of people choose Python.org, the same for me!\n\n:::{.callout-caution}\nThis way ships a tool to create development environments (`venv`). However, `venv` cannot create environments with different Python versions (you're tied to the one you downloaded) and certain packages will require extra steps to be installed. Therefore, it **is not** for everyone.\n:::\n\nJuan chose to use `conda`. As I am learning Docker, I choose Docker for this tutorial.\n\nHow do people create isolated development environments? -> The most popular is `Virtualenv`. But normally when doing an analysis task, I use `venv` which is built-in python lib. Recently I followed my dev team to use `pipenv`, I do also see `poetry` is worth-learning approach.\n\n> \"More than a half of the users of Jupyter Notebook and JupyterLab choose Conda\"\n\nAs I think a model which is not deployed yet is useless model, I choose VS Code and Docker - more deployment-oriented. \n\n## summary\n\n> For the user, the most salient distinction is probably this: pip installs python packages within any environment; conda installs any package within conda environments.\n> \n> —Jake Vanderplas\n\nHowever, I will be using `pipenv` to achieve what Juan done in upcoming sections. I will specify version of each package I used.\n\n## `pip` and `PyPI`\n\n`pip` is the default Python installer. By default, it fetches packages from <https://pypi.org/>, which is the community repository for Python packages.\n\n# 05 layout\n\nhere is my project's layout:\n\n```bash\nie-titanic-utils\n├─ src\n│  └─ ie_titanic_utils\n│     ├─ __init__.py\n│     └─ ...\n├─ tests\n│  └─ ...\n├─ .gitignore\n├─ README.md\n└─ pyproject.toml\n```\n\n- The `src/package_name` contains the source code of the library. `package_name` must be Python identifier. It should contain a `__init__.py` that can be empty;\n- The `tests` directory contains the tests. It must not contain any `__init__.py` because it's not meant to be imported as a package. In very specific cases it's included inside `src/package_name`;\n- Every project contains a `README.md` that at least explains what the project is;\n- `pyproject.toml` contains the metadata of the project. The absolutely required fields are `module`, `author`, and some extra information that tells Python how to install the package.\n\n## creating a package\n\n1. run `flit init` to create the metadata\n\n```bash\n ie-titanic-utils  flit init\npyproject.toml exists - overwrite it? [y/N]: y\nModule name [ie_titanic_utils]: ie_utils\nAuthor: Tuan Le Khac\nAuthor email: tuan.lekhac0905@gmail.com\nHome page: \nChoose a license (see http://choosealicense.com/ for more info)\n1. MIT - simple and permissive\n2. Apache - explicitly grants patent rights\n3. GPL - ensures that code based on this is shared with the same terms\n4. Skip - choose a license later\nEnter 1-4: 4\n\nWritten pyproject.toml; edit that file to add optional extra info.\n```\n\n2. place some code under the source directory. In `__init__.py` there must be a docstring giving a description of the project and a `__version__` variable indicating the version:\n\n```{.python filename=\"__init__.py\"}\n\"\"\"IE utils (test package).\"\"\"\n\n__version__ = \"0.1.0\"\n```\n\n3. Install the code using `pip install`! (this did not work for me currently. edit: the project name should match the `src/package_name` omg)\n\n```bash\n ie-titanic-utils  pip install .\nProcessing .ie-titanic-utils\n...\nSuccessfully installed ie_titanic_utils-0.1.0\n ie-titanic-utils  python\nPython 3.11.4 (tags/v3.11.4:d2340ef, Jun  7 2023, 05:45:37) [MSC v.1934 64 bit (AMD64)] on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import ie_titanic_utils\n>>> ie_titanic_utils.__version__\n'0.1.0'\n>>>    \n```\n\n4. `readme.md` and a `.gitignore` files were created.\n5. commit the change\n\n```bash\ngit checkout -b first_module # i should be using switch (-c) haha, checkout is old syntax\ngit status\ngit add .\ngit commit -m \"initial very first module\"\ngit checkout master\n\n ie-titanic-utils  git merge --no-ff first_module\nMerge made by the 'ort' strategy.\n pyproject.toml                    | 30 ++++++++++++++++++++++++++++++\n src/ie_titanic_utils/__init__.py  |  6 ++++++\n src/ie_titanic_utils/str_utils.py |  6 ++++++\n 3 files changed, 42 insertions(+)\n create mode 100644 pyproject.toml\n create mode 100644 src/ie_titanic_utils/__init__.py\n create mode 100644 src/ie_titanic_utils/str_utils.py\n\ngit branch -d first_module\n# git push origin master\n# as I will not upload this code to GitHub\n# https://stackoverflow.com/questions/32238616/git-push-fatal-origin-does-not-appear-to-be-a-git-repository-fatal-could-n\n```\n\nNow if I log the git, I will see this:\n\n```bash\n ie-titanic-utils  git log --graph --oneline --decorate --all\n*   39105c7 (HEAD -> master) Merge branch 'first_module'\n|\n| * 7a33844 initial very first module\n|/\n* 793bd67 initial commit\n```\n\nYeah til now I can create a \"package\" in my computer and install so I can use it **globally**. But I have not use any env management yet.\n\n## intermezzo: version numbers\n\n+ Version numbers for Python packages are explained in [PEP 440](https://www.python.org/dev/peps/pep-0440/)\n+ For libraries, the most widely used convention is [semantic versioning](https://semver.org/): X.Y.Z\n  - Z **must** be incremented if only backwards compatible bug fixes are introduced (a bug fix is defined as an internal change that fixes incorrect behavior)\n  - Y **must** be incremented every time there is new, backwards-compatible functionality\n  - X **must** be incremented every time there are backwards-incompatible changes\n+ Between releases, the version should have the `.dev0` suffix\n+ Recommendation: start with 0.1.dev0 (development version), then make a `0.1.0` release, then progress to `0.1.1` for quick fixes and `0.2.0` for new functionality, and when you want to make a promise of relative stability jump to `1.0.0`.\n+ For applications, other conventions are more appropriate, like [calendar versioning](https://calver.org/): `[YY]YY.MM.??`\n\n## project requirements\n\nSometimes our project will depend on third-party libraries (pandas, scikit-learn). To make pip install those dependencies automatically, we can add them to our `pyproject.toml` under the `[tool.flit.metadata]` section, using the `requires` option:\n\n```md\n[build-system]\nrequires = [\"flit_core>=3.4\"]\nbuild-backend = \"flit_core.buildapi\"\n\n[project]\nname = \"ie_titanic_utils\"\nauthors = [{name = \"Tuan Le Khac\", email = \"tuan.lekhac0905@gmail.com\"}]\nreadme = \"readme.md\"\nrequires-python = \">=3.11\"\ndynamic = [\"version\", \"description\"]\nclassifiers = [\n    \"Programming Language :: Python :: 3\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\nrequires = [\n    \"pandas\",\n    \"matplotlib>=2\",\n]\n```\n\nWe might want to specify *optional* dependencies that should only be installed upon request, or for some specific purposes. A typical example will be development dependencies: we will need things like `pytest` and `black`, but we don't want the user to install them as part as our library. To do that, we can specify *groups* of optional dependencies under the `tool.flit.metadata.requires-extra` section:\n\n```md\nIn my case, I use `project.optional-dependencies`: flit_core.config.ConfigError: Use [project] table for metadata or [tool.flit.metadata], not both.\n[project.optional-dependencies]\ndev = [\n    \"pytest>=6.0\",\n    \"black>=20.8b1\",\n]\n```\n\nThat way, they will only get installed when `[dev]` is added after the name of our library:\n\n```bash\n ie-titanic-utils  pip install .[dev]\n# Successfully installed black-24.4.2 ie_titanic_utils-0.1.0 iniconfig-2.0.0 pytest-8.2.2\n```\n\n# 06 [unit test](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/06_unit-tests.ipynb)\n\n> If you use software that lacks automated tests, you are the tests.\n> \n> — Jenny Bryan (@JennyBryan) [September 22, 2018](https://x.com/JennyBryan/status/1043307291909316609?ref_src=twsrc%5Etfw)\n\nTesting is **essential**. Computers excel at doing repetitive tasks: they basically never make mistakes (the mistake might be in what we told the computer to do). Humans, on the other hand, fail more often, especially under pressure, or on Friday afternoons and Monday mornings. Therefore, instead of letting the humans be the tests, we will use the computer to **frequently verify that our software works as specified**.\n\nI will be using `pytest` to achieve this.\n\n## test-driven development\n\nThe \"test-driven development mantra\" is <span style=\"color:red;font-weight:bold;\">Red</span> - <span style=\"color:green;font-weight:bold;\">Green</span> - <span style=\"color:grey;font-weight:bold;\">Refactor</span>:\n\n:::{layout-ncol=\"1\"}\n![Make it work. Make it right. Make it fast.](https://raw.githubusercontent.com/astrojuanlu/ie-mbd-advanced-python/e2224276f91529280ebfcd42ddc7dc22cf0d2010/img/red-green-refactor.png)\n:::\n\n1. Write a test. <span style=\"color:red;font-weight:bold;\">Watch it fail</span>.\n2. Write just enough code to <span style=\"color:green;font-weight:bold;\">pass the test</span>.\n3. Improve the code without breaking the test.\n\nRepeat.\n\n## testing in Python\n\nSummary: use `pytest`. Everybody does. It rocks.\n\n[pytest](https://docs.pytest.org/en/8.2.x/) is a testing framework for Python that makes writing tests extremely easy. It is much more powerful than the standard library equivalent, `unittest`. We can use by install it first `pip install pytest`.\n\nWe can write a function that test the `tokenize` funtion:\n\n```{.python filename=\"tests/test_tokenize.py\"}\nfrom ie_titanic_utils import tokenize  # This will fail right away!\n\n\ndef test_tokenize_returns_expected_list():\n    sentence = \"This is a sentence\"\n    expected_tokens = [\"This\", \"is\", \"a\", \"sentence\"]\n\n    tokens = tokenize(sentence)\n\n    assert tokens == expected_tokens\n```\n\nand we run it from the command line:\n\n```bash\n ie-titanic-utils  pytest\n============================================================================================ test session starts ============================================================================================\nplatform win32 -- Python 3.11.4, pytest-8.2.2, pluggy-1.5.0\nrootdir: .ie-titanic-utils\nconfigfile: pyproject.toml\nplugins: anyio-3.7.1, time-machine-2.14.0\ncollected 1 item\n\nteststest_tokenize.py .                                                                                                                                                                               [100%] \n\n============================================================================================= 1 passed in 0.02s ============================================================================================= \n```\n\nThe test successed after I fixed the `__init__.py`:\n\n```{.python filename=\"src/./__init__.py\"}\nfrom ie_titanic_utils.str_utils import tokenize\n__all__ = [\"tokenize\"]\n```\n\n# 07&08 [oop](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/07-08_object-oriented-programming.ipynb)\n\n## what are \"objects\" anyway?\n\nlike pandas's `DataFrame` or matplotlib's `Figure`, an *object* is sthg that has:\n\n- object-bound variables: call **properties**;\n- object-bound functions: call **methods**.\n\nif the object's properties can change, we say they have **states**, in that case they are **mutable**. otherwise, they are **stateless** and **immutable**. a typical example is list (mutable) and tuple (immutable).\n\n::: {#420bf50e .cell execution_count=3}\n``` {.python .cell-code}\nmy_list = [1, 2, 3]\nprint(my_list)\nmy_list.append(4)\nprint(my_list)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1, 2, 3]\n[1, 2, 3, 4]\n```\n:::\n:::\n\n\n::: {#3893a277 .cell execution_count=4}\n``` {.python .cell-code}\n# The operator that creates tuples is not parentheses:\n# is the comma!\nmy_tuple = 1, 2, 3  # Notice that I don't need parentheses!\nmy_tuple\n```\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n(1, 2, 3)\n```\n:::\n:::\n\n\n::: {#62ffbdb1 .cell execution_count=5}\n``` {.python .cell-code}\nprint(dir(my_tuple))  # Nothing that allows us to change the state of the tuple\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n['__add__', '__class__', '__class_getitem__', '__contains__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getnewargs__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__mul__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__rmul__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', 'count', 'index']\n```\n:::\n:::\n\n\n::: {#38108e09 .cell execution_count=6}\n``` {.python .cell-code}\nmy_tuple[0] = 99 # This wont work, \"TypeError: 'tuple' object does not support item assignment\"\n```\n:::\n\n\n::: {.callout-note}\nImmutable objects have the advantage that they can be **hashed**, that is: they can be transformed, using some cryptographical function, into something that uniquely represents that object. Mutable objects can't, because the hash would have to change every time the state of the object changed. **Dictionary keys have to be hashable objects**.\n:::\n\n::: {#12fa6316 .cell execution_count=7}\n``` {.python .cell-code}\n{\n    my_tuple: \"my_tuple\"\n}\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\n{(1, 2, 3): 'my_tuple'}\n```\n:::\n:::\n\n\n::: {#249e2363 .cell execution_count=8}\n``` {.python .cell-code}\nhash(my_tuple)\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n529344067295497451\n```\n:::\n:::\n\n\n::: {#5ef6beee .cell execution_count=9}\n``` {.python .cell-code}\n# this wont work: \"TypeError: unhashable type: 'list'\"\n{\n    my_list: \"my_list\"\n}\n```\n:::\n\n\n::: {#0096641b .cell execution_count=10}\n``` {.python .cell-code}\n# this wont work: \"TypeError: unhashable type: 'list'\"\nhash(my_list)\n```\n:::\n\n\n## classes and instances\n\nobjects are defined by **instantiating a class**. a class is a **template** for objects, where we define it's behaviours, an **instance** is a particular realization of that class.\n\n### Example\n\nwe want model the `User` of our company's product, to later study their behaviours:\n\n::: {#4d14860f .cell execution_count=11}\n``` {.python .cell-code}\nclass User:\n    pass\ntype(User)\n```\n\n::: {.cell-output .cell-output-display execution_count=6}\n```\ntype\n```\n:::\n:::\n\n\n`User` class is of type `type`, which means that is can be used to created new objects. Let's create 2 instances:\n\n::: {#30996245 .cell execution_count=12}\n``` {.python .cell-code}\nuser1 = User()\nuser2 = User()\nprint(user1)\nprint(user2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<__main__.User object at 0x000001B1AD8D4F90>\n<__main__.User object at 0x000001B1AD8D4D90>\n```\n:::\n:::\n\n\nwith a slight abuse of notation, we would say we have 2 `User` objects, or just 2 `User`s.\n\n### Using the instance: `self`\n\nlet's add a very simple **method** to demonstrate *explicit* `self`, a very important concept. a method is like a function bounded to the object, an can use it's properties:\n\n::: {#ba8a0d18 .cell execution_count=13}\n``` {.python .cell-code}\nclass User:\n    def whoami(self):\n        print(f'This is : {self}')\n```\n:::\n\n\n::: {#2441e1cb .cell execution_count=14}\n``` {.python .cell-code}\nuser1 = User()\nuser1.whoami()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is : <__main__.User object at 0x000001B1AD8D4590>\n```\n:::\n:::\n\n\nwhy are methods (instead of plain functions) interesting? Because of **duck typing**:\n\n> \"If it walks like a duck and it quacks like a duck, then it must be a duck\" -- <https://en.wikipedia.org/wiki/Duck_typing>\n\nif something has a method that I need, I don't care about its type.\n\n::: {#5032dcea .cell execution_count=15}\n``` {.python .cell-code}\ndef do_stuff(obj):\n    return obj.mean()\n```\n:::\n\n\n::: {#e0da8b5a .cell execution_count=16}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\n\nprint(do_stuff(np.arange(5)))\nprint(do_stuff(pd.Series([0, 1, 2, 3, 4])))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.0\n2.0\n```\n:::\n:::\n\n\nnotice how we called `user1.test()` **without passing an extra argument**? This is because Python is automatically passing the instance. It's the equivalent of doing this (**never do this**):\n\n::: {#8b163d53 .cell execution_count=17}\n``` {.python .cell-code}\nUser.whoami(user1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is : <__main__.User object at 0x000001B1AD8D4590>\n```\n:::\n:::\n\n\nin fact, if we define a method without a first parameter, it will fail when we call it:\n\n::: {#5bf4beeb .cell execution_count=18}\n``` {.python .cell-code}\nclass TestClass:\n    def test():\n        pass  # Don't do anything\n\nt = TestClass()\nt.test()  # Fails: \"TypeError: test() takes 0 positional arguments but 1 was given\"\n```\n:::\n\n\nthis first parameter can be called anything, but **everybody uses `self`**. Remember, conventions are important to minimize surprise and enhance collaboration!\n\n### intermezzo: f-strings\n\n::: {#669cec83 .cell execution_count=19}\n``` {.python .cell-code}\nprint(f\"This is {user1}\")  # Python >= 3.6\nprint(\"This is {}\".format(user1))  # Python < 3.6, equivalent\nprint(User.whoami(user1))  # DON'T use! (Although it's equivalent)   \n# %timeit User.whoami(user1)  # They have about the same performance \n# %timeit user1.whoami()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nThis is <__main__.User object at 0x000001B1AD8D4590>\nThis is <__main__.User object at 0x000001B1AD8D4590>\nThis is : <__main__.User object at 0x000001B1AD8D4590>\nNone\n```\n:::\n:::\n\n\n### initializing our instances\n\nThe ellipsis (`...`) is a built-in constant in Python. It's an instance of the `ellipsis` (dấu chấm lửng) class.\n\n::: {#dd7c9d48 .cell execution_count=20}\n``` {.python .cell-code}\n...\n```\n\n::: {.cell-output .cell-output-display execution_count=14}\n```\nEllipsis\n```\n:::\n:::\n\n\ncommon uses of ellipsis:\n\n- as a placeholder in function definitions or class bodies\n- in type hinting (especially for variable-length tuples)\n- in slicing operations (especially for multidimensional arrays in libraries like NumPy)\n\n::: {#9042a8b1 .cell execution_count=21}\n``` {.python .cell-code}\n# As a placeholder\ndef function_to_be_implemented_later():\n    ...\n\n# In type hinting\nfrom typing import Tuple\n\ndef process_points(*points: Tuple[int, ...]) -> None:\n    for point in points:\n        print(f\"Processing point: {point}\")\n\n# Usage\nprocess_points((1, 2), (3, 4, 5), (6,))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nProcessing point: (1, 2)\nProcessing point: (3, 4, 5)\nProcessing point: (6,)\n```\n:::\n:::\n\n\n::: {#82041adf .cell execution_count=22}\n``` {.python .cell-code}\nuser1.this_property = ...  # \"99\", whatever\nuser1.this_property\n```\n\n::: {.cell-output .cell-output-display execution_count=16}\n```\nEllipsis\n```\n:::\n:::\n\n\nhowever, this is considered a bad practice, and can confuse editors and static analysis tools. These properties should be specified on creation, in a way that I cannot have a user without `name` and `signup_date`. Python provides us a special method, `__init__` (this should not be confused with file `__init__.py` we put to project to tell Python our code is a package), that **initializes**[^1] the object:\n\n[^1]: sometimes this method is called the *constructor*, but strictly speaking, in Python the *constructor* is `__new__` and you should not use it. The difference is that the *constructor* returns an instance, whereas the **initializer** works with an already created instance and should return `None`.\n\n::: {#ab86dd9f .cell execution_count=23}\n``` {.python .cell-code}\nclass User:\n    # \"dunder init\" = double underscore init\n    def __init__(self, name, signup_date):\n        self.name = name\n        self.signup_date = signup_date\n```\n:::\n\n\n::: {#9423fb8d .cell execution_count=24}\n``` {.python .cell-code}\nimport datetime as dt\nuser1 = User(name=\"John Doe\", signup_date=dt.datetime.now())\nprint(user1.name, user1.signup_date, sep='\\n')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nJohn Doe\n2024-08-01 23:07:08.587740\n```\n:::\n:::\n\n\nthat's something! However, there are several things we can improve:\n\n- it can be cumbersome to specify the date every time, and it would be nice to have some default.\n- the default representation of the instances contains some hexadecimal memory address and nothing else. It would be nice to at least see the user name and the signup date\n- nothing stops me from changing the name and signup_date of a existing user:\n\n### exercise\n\n- make `signup_date` optional by providing a default value;\n- make the `__repr__` method return a string containing the `name` and `signup_date`, which will override the default.\n\n::: {#fd72f5b4 .cell execution_count=25}\n``` {.python .cell-code}\nclass User:\n    def __init__(self, name, signup_date=None):\n        if signup_date is None:\n            signup_date = dt.datetime.now() # Watch out with default parameters! They are created when the function is defined.\n\n        self.name = name\n        self.signup_date = signup_date\n\n    def __repr__(self):\n        return f\"User(name='{self.name}', signup_date={repr(self.signup_date)})\"\n```\n:::\n\n\n::: {#bd10d931 .cell execution_count=26}\n``` {.python .cell-code}\nuser1 = User(\"John Doe\")\nuser1\n```\n\n::: {.cell-output .cell-output-display execution_count=20}\n```\nUser(name='John Doe', signup_date=datetime.datetime(2024, 8, 1, 23, 7, 8, 618751))\n```\n:::\n:::\n\n\n### extra: date formatting\n\n::: {#fc4b84ad .cell execution_count=27}\n``` {.python .cell-code}\ndt.datetime.now().isoformat()  # ISO 8601\n# If you don't like it, there's http://strftime.org/\n```\n\n::: {.cell-output .cell-output-display execution_count=21}\n```\n'2024-08-01T23:07:08.625045'\n```\n:::\n:::\n\n\n::: {#b23b8c74 .cell execution_count=28}\n``` {.python .cell-code}\nuser1.signup_date.strftime(\"%Y ::: %d\")\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\n'2024 ::: 01'\n```\n:::\n:::\n\n\n### protecting properties\n\nin Python, there are *no private attributes* (neither properties nor methods), and in fact everything can be accessed [^1]. However, we can \"hide\" them by default in autocomplete and other environments by using a leading underscore `_`: this is usually called **protected variables**.\n\nthere is a common pattern in which, if I want to make some property read-only, we can:\n\n- make it protected\n- create a \"getter\" using the @property decorator, which gets the value of the protected property with a public name\n\n[^1]: This philosophy used to be summarized by the sentence \"we are all consenting adults here\", which is nowadays being less used.\n\n::: {#b008d693 .cell execution_count=29}\n``` {.python .cell-code}\nclass User:\n    def __init__(self, name, signup_date=None):\n        if signup_date is None:\n            signup_date = dt.datetime.now()\n\n        self._name = name\n        self._signup_date = signup_date\n\n    @property\n    def name(self):\n        return self._name\n\n    @property\n    def signup_date(self):\n        return self._signup_date\n\n    def __repr__(self):\n        return f\"User(name='{self.name}', signup_date='{self.signup_date}')\"\n```\n:::\n\n\n::: {#e9a3b5f8 .cell execution_count=30}\n``` {.python .cell-code}\nuser1 = User(\"Tuan Le\")\nuser1.name\n```\n\n::: {.cell-output .cell-output-display execution_count=24}\n```\n'Tuan Le'\n```\n:::\n:::\n\n\n::: {#9fb2282d .cell execution_count=31}\n``` {.python .cell-code}\n# this wont work: \"AttributeError: can't set attribute\"\nuser1.name = \"Tan Le\"\n```\n:::\n\n\n::: {.callout-important}\nIf you see tutorials mentioning \"true private variables\", they are wrong!\n:::\n\n::: {#88ed0501 .cell execution_count=32}\n``` {.python .cell-code}\nclass Test:\n    def __init__(self, name):\n        self.__name = name  # Not what you think!\nt1 = Test(\"This name\")\n```\n:::\n\n\n::: {#e79d62f4 .cell execution_count=33}\n``` {.python .cell-code}\n# this wont work\nt1.__name\n```\n:::\n\n\n::: {#ed82f250 .cell execution_count=34}\n``` {.python .cell-code}\nt1._Test__name  # These are *NOT* \"private\" properties\n```\n\n::: {.cell-output .cell-output-display execution_count=26}\n```\n'This name'\n```\n:::\n:::\n\n\n::: {.callout-note}\nThe behavior you're experiencing is due to a feature in Python called \"name mangling\" for private attributes. Let's break down what's happening:\n\nDouble underscore prefix:\n\n- When you define an attribute with a double underscore prefix (__) in a class, Python automatically mangles the name to avoid naming conflicts in inherited classes.\n- Name mangling process: Python changes the name from __name to _ClassName__name. In your case, it becomes _Test__name.\n- Accessing the attribute: Because of this name mangling, you can't access t1.__name directly. Instead, you would need to use the mangled name.\n\n::: {#950c80df .cell execution_count=35}\n``` {.python .cell-code}\nclass Test:\n    def __init__(self, name):\n        self.__name = name  # This gets mangled\n\nt1 = Test(\"This name\")\n\n# This will raise an AttributeError\ntry:\n    print(t1.__name)\nexcept AttributeError as e:\n    print(f\"AttributeError: {e}\")\n\n# This will work\nprint(t1._Test__name)\n\n# You can see all attributes, including mangled ones\nprint(dir(t1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAttributeError: 'Test' object has no attribute '__name'\nThis name\n['_Test__name', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']\n```\n:::\n:::\n\n\n:::\n\n\n## inheritance\n\n::: {#d54bc550 .cell execution_count=36}\n``` {.python .cell-code}\nclass SpecialUser(User):\n    def __init__(self, name, age, signup_date=None):\n        # Initializes self._name and self._signup_date\n        super().__init__(name, signup_date)\n\n        self._age = age\n\n    @property\n    def age(self):\n        return self._age\n\n    def greet(self):\n        print(f\"Hi! I'm {self.name}\")\n```\n:::\n\n\n::: {#dd17b672 .cell execution_count=37}\n``` {.python .cell-code}\ns_user1 = SpecialUser(\"John Doe\", 27)\n#s_user1\n```\n:::\n\n\n::: {#bb9e12fb .cell execution_count=38}\n``` {.python .cell-code}\ns_user1.name\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\n'John Doe'\n```\n:::\n:::\n\n\n::: {#7742acf4 .cell execution_count=39}\n``` {.python .cell-code}\ns_user1.greet()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nHi! I'm John Doe\n```\n:::\n:::\n\n\n- the diamond problem: <https://www.wikiwand.com/en/Multiple_inheritance#/The_diamond_problem>\n- ???: <https://softwareengineering.stackexchange.com/questions/238176/why-would-square-inheriting-from-rectangle-be-problematic-if-we-override-the-set/238184#238184>\n- liskov substitution principle: <https://www.wikiwand.com/en/Liskov_substitution_principle>\n- composition and inheritance: <https://www.thedigitalcatonline.com/blog/2014/08/20/python-3-oop-part-3-delegation-composition-and-inheritance/>\n\n### more special methods\n\ngo search for python data model\n\n# 09&10 [flask](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/09-10_flask.ipynb)\n\n- flask is a \"lightweight framework\" or a \"microframework\". \"It is designed to make getting started quick and easy, with the ability to scale up to complex applications\", and therefore requires less context to get started with;\n- django is a \"batteries included\" framework that is more focused on good practices and encouraging a \"clean, pragmatic design\". It's more complex and requires more experience to master.\n\n# [conclusion](https://github.com/astrojuanlu/ie-mbd-advanced-python/blob/main/sessions/99_conclusion.ipynb)\n\n## where do we go from here\n\n- Keep improving the art of Python packaging\n- Explore other options for high performance Python\n- Help \"bridging the gap\"\n- Engage with the (open source) Python community\n\n## keep improving the art of python packaging\n\n- recommend: `pip-tools` + `requirements.in` = `requirements.txt`\n- Poetry, Pipenv... Yes, they work, but they are way more complex and have \"lock-in\"\n- All companies I worked for struggle sooner or later with their code deployment practices. Now, you know better\n\n## explore other options for high performance python\n\n- Juan mentioned: Numba, Modin, Vaex, Dask, Spark, Coiled, Prefect\n- Now we have more: polar, pandas 2.0, aiflow, dagster, dbt, etc  \n\n:::{layout-ncol=\"1\"}\n![stolen from the lecture](setup_py_br.png)\n:::\n\n# other resources\n\n1. [NBViewer](https://nbviewer.org/github/astrojuanlu/ie-mbd-advanced-python/tree/main/) for this lecture;\n2. [PyData](https://pydata.org/), a community for developers and users of open source data tools;\n3. [Pro Git](https://git-scm.com/book/en/v2/), `--distributed-is-the-new-centralized`;\n4. [Pull Requests](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/about-pull-requests);\n5. [Merge Requests](https://docs.gitlab.com/ee/user/project/merge_requests/index.html);\n6. [Git Workflow](https://www.asmeurer.com/git-workflow/), the git workflow for contributing to open source repositories;\n7. [Git Ignore](https://www.toptal.com/developers/gitignore) builder;\n8. [Git commit --amend](https://www.atlassian.com/git/tutorials/rewriting-history), rewriting history;\n9. [The right way to distribute Python code](https://packaging.python.org/en/latest/tutorials/packaging-projects/)\n10. [Python packaging](https://docs.python.org/3/tutorial/modules.html#packages)\n11. [Pytest](https://docs.pytest.org/en/8.2.x/).\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}