{
  "hash": "a09ea405192edb4def0defcde922547c",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Recap: So you want to be a Python expert?\"\ndescription: \"by James Powell, PyData Seattle 2017\"\nauthor:\n  - name: \"Tuan Le Khac\"\n    url: https://lktuan.github.io/\ncategories: [python, pydata] \ndate: 07-10-2024\ndate-modified: 07-16-2024\nimage: pydata-logo-final.png\ncode-tools: true\ncode-fold: show\ncode-annotations: hover\ndraft: false\ncss: html/styles.scss\nfig-cap-location: bottom\neditor: visual\nformat:\n  html:\n    code-overflow: wrap\n---\n\nðŸ”¥ source: [**James Powell: So you want to be a Python expert? | PyData Seattle 2017**](https://www.youtube.com/watch?v=cKPlPJyQrt4)\n\n# what is he gonna present?\n\n- something deeply behind the Zen of Python;\n- metaphors and programming in Python;\n- python is not only scripting language, he will be introducing 4 features of Python and the way experts would think about these features;\n- a lot of fundamental details of how these feature work but very little talk about we can conceptualize these features in the broader sense of what they mean for modeling core problem. so 4 features you might have heared before and couple of the core mental models how you can think about, an how you can think about python as a whole, wrapping everything together;\n- you will see me stumble to understand that in case you dont utd or dont have docs memorized, it's alright, the target is to know what they are and what they mean;\n- the talk presumes you to have a baseline of Python, but in case you a new to Python he believes there are cores you can take away.\n\n\n:::{layout-ncol=\"1\"}\n![James Powell on PyData Seattle 2017](James%20Powell_%20So%20you%20want%20to%20be%20a%20Python%20expert_%20_%20PyData%20Seattle%202017%205-37%20screenshot.png)\n:::\n\n# data model protocol (or dunder method)\n\nassume we have a data model with Polynomial object intitially do nothing, why I need 4 lines (instead of 2 lines) to create 2 Polynominals. How can I create and assign coefficients together.\n\n::: {#935bce05 .cell execution_count=1}\n``` {.python .cell-code}\nclass Polynomial:\n    pass\np1= Polynomial()\np2= Polynomial()\np1.coeffs = 1, 2, 3 #  x^2 + 2x + 3\np2.coeffs = 3, 4, 3 # 3x^2 + 4x + 3\n```\n:::\n\n\nthe answer is using a constructor `__init__`, then we can compact our code like this:\n\n::: {#c80a8e25 .cell execution_count=2}\n``` {.python .cell-code}\nclass Polynomial:\n    def __init__(self, *coeffs):\n        self.coeffs = coeffs\n\np1 = Polynomial(1, 2, 3 ) #  x^2 + 2x + 3\np2 = Polynomial(3, 4, 3 ) # 3x^2 + 4x + 3\n```\n:::\n\n\nbut if we print our objects in the terminal, they look so ugly. We miss the method that actually call `repr(obj)` when we run `obj`:\n\n:::{layout-ncol=\"1\"}\n![The need of `__repr__`](1_repr.png)\n:::\n\nthat's what `__repr__` for, a printable representation of the class:\n\n::: {#2f115390 .cell execution_count=3}\n``` {.python .cell-code}\nclass Polynomial:\n    def __init__(self, *coeffs):\n        self.coeffs = coeffs\n\n    def __repr__(self):\n        return 'Polynomial(*{!r})'.format(self.coeffs)\n\n\np1 = Polynomial(1, 2, 3)  #  x^2 + 2x + 3\np2 = Polynomial(3, 4, 3)  # 3x^2 + 4x + 3\n```\n:::\n\n\nthe next thing we wanna do is to add Polinimials together `p1 + p2`.  \n\n::: {#ee94fb92 .cell execution_count=4}\n``` {.python .cell-code}\n    def __add__(self, other):\n        return Polynomial(*(x + y for x, y in zip(self.coeffs, other.coeffs)))\n```\n:::\n\n\n:::{.callout-note}\nWhat is pattern here? I have some behaviours that I want to implement, and I write some **underscore** (`__x__`) funtions. We call them dunder or underscore methods.\n\nTry google \"data model\" and we'll a bunch of documents that list all method to implement the principle behaviours of our objects. There are top-level functions of top-level syntaxes that corresponding to `__`.\n\nBut there are smthg more fundamental here, when I want to:\n\n- x + y -> `__add__`;\n- initialize x -> `__init__`;\n- repr(x) -> `__repr__`.\n\nThen what if we want to implement the `len()` (return the length, which is popular know Python function) -> naturally we'll be thinking of `__len__`.\n\n::: {#705b098f .cell execution_count=5}\n``` {.python .cell-code}\n    def __len__(self):\n        return len(self.coeffs)\n```\n:::\n\n\n:::\n\n\nThe Python data model is a means by which you can protocols. Thos protocols have abstract meaning depending on the object itself. We tight the behaviours to top-level **syntaxes** and **functions**.\n\nSimilarly, if we do see the object Polynomial a executable, callable thing, we can implement a `__call__` which will turn our class to function, in this case we cant imagine such thing, so pass.\n\nâœ There are 3 core patterns we want to understand and remember in Python to really understand object orientation in Python:\n\n1. The protocol view of Python;\n2. The buil-in inheritance protocol;\n3. Some caveats around how OOP in Python works.\n\nWhich will be continue to present in this video is jumping into a very tricky metaphor a feature we may have heard of.\n\n# meta class\n\nimagine there are 2 groups working on some piece of software. one is core infrastructure of the group and they write `library` code, the other group is devloper group, they write `user` code. the developer use `library` code to accomplish actual business objectives. the core team less cares about business problem, they focus on technical stuffs.\n\nyou are in the dev team and there is no way to change to code of `library.py`. in what circumstance the code of `user` can break -> there is no `foo` method! To avoid that, we could simply write a test that call `bar()`, then we could know if it fails before production environment's runtime.\n\nis there anything simpler to know the ability to fail before hit run time in production env? -> use `assert` to check existence of the attribute. we will have an early warning right before the class was initiated.\n\n:::{layout-ncol=\"1\"}\n![we can know if the core team change the function name to \"food\"](2_assert.png)\n:::\n\nby this way we are enforcing constraints on the base class from the derived class.\n\nnow we move to a reverse situation, you are the core structure writer and have to deal with the meathead in the business unit that actually using/abusing/missusing your code ~ you have no idea what are they doing. you write the `Base` class with the assumption and some responsible developer in the BU will go and implement the `bar` method.\n\n:::{layout-ncol=\"1\"}\n![what if you stand on the left side pane](3_reverse_sit.png)\n:::\n\nyou have no ability to change and even have no idea where the code on the right pane sit. we can not use `hasattr()` for this particular situation. the first method is to use `try ... catch ...`, but it only catches in runtime and we will miss catching it before it goes to production env.\n\n:::{callout-note}\nThe reason that we could call Python a **protocol orientated language** is not just because the Python data model the object model is protocol orientated but that the entire Python language itself has a notion of hooks and protocols and safety valves within it.\n\nPython is much much simpler language, the code run linearly from top to bottom. And the class statement in Python is actually an executable code. We can write this:\n\n::: {#459c7412 .cell execution_count=6}\n``` {.python .cell-code}\nfor _ in range(10):\n  class Base: pass\n\n# or the same thing in other way\n\nclass Base:\n  for _ in range(10):\n    def bar(self):\n      return 'bar'\n```\n:::\n\n\nOnly the last one will survive. Python accepts this syntax because it's class is **fundamentally executable**.\n:::\n\nLet's get into something more interesting! create a class inside a function and use a function in a module in standard libbrary in Python called `dis`.\n\n::: {#e9bb28e0 .cell execution_count=7}\n``` {.python .cell-code}\n# create a class inside a function\ndef _():\n  class Base:\n    pass\n\n# dis stands for disassemble\nfrom dis import dis\n```\n:::\n\n\nlet's 'dis' - stands for disassemble - to see what happen in the bytecode. there are actually things in Python bytecode call `LOAD_BUILD_CLASS`, it's actual executable runtime instruction in the Python interpreter for create a class.\n\n:::{layout-ncol=\"1\"}\n![disassemble](4_dis.png)\n:::\n\nat the first section of this lecture, we saw some **correspondence** between top-level syntac or function AND some underscore method that implements that syntax or function. there should be also top-level mechanism, not explicitly syntax or function, with the process of building a class. there is a build-ins function called `__build_class__`.\n\n::: {#0f955f2e .cell execution_count=8}\n``` {.python .cell-code}\nold_bc = __build_class__\n\ndef my_bc(func, name, base=None, **kw):\n  if base is Base:\n    print('check if the bar method is defined')\n  if base is not None:\n    return old_bc(func, name, base, **kw)\n  return old_bc(func, name, **kw)\n\nimport builtins\nbuiltins.__build_class__ = my_bc\n```\n:::\n\n\n:::{layout-ncol=\"1\"}\n![`__build_class__`, we can check if the `bar` method is implemented, Python is **protocal oriented language**!](5_build_class.png)\n:::\n\nIt's actually quite a common pattern and quite a fundamental piece of Python almost everything that a Python language does in an execution context like building classes, creating functions, importing modules you can find a way to **hook** into that. once you can find a way to hook into that you can start doing things that you want to do like check is my user code going to break from the perspective the library author. \n\nThe most important thing here is **understanding existence of this pattern**, knowing that there are options solving such problem, and there are even better approachs.\n\n## There are 2 fundamental ways that people ussually use to solve this\n\n### 1. meta class\n\n[[futher discussion](https://stackoverflow.com/questions/395982/metaclass-new-cls-and-super-what-is-the-mechanism-exactly)]{.aside}\n\n::: {#38e91bf5 .cell execution_count=9}\n``` {.python .cell-code}\n# meta classes are merely derived from `type`\nclass BaseMeta(type):\n    def __new__(cls, name, bases, namespace):\n        print('BaseMeta.__new__', cls, name, bases, namespace)\n        if name != 'Base' and 'bar' not in namespace:\n            raise TypeError(\"Bad User class, 'bar' is not defined\")\n        return super().__new__(cls, name, bases, namespace)\n\n\n# then our Base should be derived from BaseMeta\nclass Base(metaclass=BaseMeta):\n    def foo(self):\n        return self.bar()\n```\n:::\n\n\n:::{layout-ncol=\"1\"}\n![metaclass](6_meta_class.png)\n:::\n\nThat's it! you can control, constraint the derived class from the base class in class hierachy.\n\n### 2. `__init_subclass__`\n\nWe can implement `Base` like this:\n\n::: {#090bfa24 .cell execution_count=10}\n``` {.python .cell-code}\nclass Base():\n    def foo(self):\n        return self.bar()\n\n    def __init_subclass__(cls, **kwargs):\n        print(\"init subclass\", cls.__dict__, kwargs)\n        if 'bar' not in cls.__dict__:\n            raise TypeError(\"Bad sub class\")\n        super().__init_subclass__(**kwargs)\n```\n:::\n\n\n# decorator\n\nWe would have met pattern like this, that's is decorator:\n\n::: {#1b733668 .cell execution_count=11}\n``` {.python .cell-code}\n@dec \ndef f():\n  pass\n```\n:::\n\n\nPython is a live language, there is no separate step that turns function definitions into bags of a set bits tagged and some elf binary or some [PE](https://en.wikipedia.org/wiki/Portable_Executable) binary somewhere. That a function definition is actually a live thing, it actually runs at runtime, there's actually executable code associated with this def `f()`.\n\n:::{layout-ncol=\"1\"}\n![we can interact with our object as Python is a live language, the function itself is a runtime object](7_interact_with_object.png)\n:::\n\nThat every Python structure that you interact with whether it's an object or a function or a generator has some **runtime life**, has some **runtime existence** you can see it in memory, you can ask it questions like what module UI were you defined in. you can even ask it very useful questions like if you use the inspect module you can say what's your source code.\n\n```bash\nî‚¶ decorators î‚° python -i .\\deco.py\n>>> from inspect import getsource\n>>> getsource(add)\n'def add(a, b=10):\\n    return a + b\\n'\n>>> print(getsource(add))\ndef add(a, b=10):\n    return a + b \n\n>>> \n```\n\nnow let's say I want to calculate how much time does it take to perform the `add`. simply we would thinking about `time`, like this:\n\n::: {#17be65b1 .cell execution_count=12}\n``` {.python .cell-code}\nfrom time import time\n\ndef add(a, b=10):\n    return a + b\n \nbefore = time()\nprint('add(10)', add(10))\nafter = time()\nprint('time_taken', after - before)\nprint('add(20, 30)', add(20, 30))\nafter = time()\nprint('time_taken', after - before)\nprint('add(\"a\", \"b\")', add(\"a\", \"b\"))\nafter = time()\nprint('time_taken', after - before)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nadd(10) 20\ntime_taken 0.0\nadd(20, 30) 50\ntime_taken 0.0\nadd(\"a\", \"b\") ab\ntime_taken 0.0\n```\n:::\n:::\n\n\nthere is something wrong here because we need to add code to everywhere we want to calculate. we see another important pattern in Python, decorator, the Python developers want you to write the simplest, stupidest, quickest thing to get the job done and get the rest of your day with your family.\n\nwe will see alot of scenarios where of cases where you can write the simple and stupidest thing to get the job done and when the task at hand becomes harder or more complex or the requirements change you can change your code in a very simple fashion to linearly extend its functionality without have to re-write it from scratch.\n\nin Python we'll see a number of different features are orientated around how do we write the simplest thing today and then when the problem gets a little bit harder we have an avenue for making our code a little bit more complex.\n\nwe can modified a `add` alittle bit\n\n::: {#9ee3649c .cell execution_count=13}\n``` {.python .cell-code}\nfrom time import time\n\ndef add(a, b=10):\n    before = time()\n    rv = a + b\n    after = time()\n    print('elapsed:', after - before)\n    return rv\n```\n:::\n\n\nBut if we have more functions, let say `sub`? We need to modify and make our code complicated. **Python is live language** that everything has some runtime representaion. We can create `timer()` which take `func`, `x`, and `y` as arguments (`x` and `y` will be forwarded to calculation function)\n\n::: {#3aca1fe5 .cell execution_count=14}\n``` {.python .cell-code}\nfrom time import time\n\ndef timer(func, x, y):\n    before = time()\n    rv = func(x,y)\n    after = time()\n    print('elapsed:', after - before)\n    return rv\n\n# and \nprint('add(20, 30)', timer(add, 20, 30))\n```\n:::\n\n\nwe can also wrapping like this, `timer()` will return a function `f`:\n\n::: {#19af8894 .cell execution_count=15}\n``` {.python .cell-code}\nfrom time import time\n\ndef timer(func):\n    def f(x, y=10):\n      before = time()\n      rv = func(x,y)\n      after = time()\n      print('elapsed:', after - before)\n      return rv\n    return f\n\n# and \nadd = timer(add)\nprint('add(20, 30)', add(20, 30))\n```\n:::\n\n\nPython provides a syntax for easily implement every behaviours of `timer()` to every function:\n\n::: {#7447cf77 .cell execution_count=16}\n``` {.python .cell-code}\n@timer\ndef add(a, b=10):\n    return a + b\n\nprint('add(20, 30)', add(20, 30))\n```\n:::\n\n\n:::{.callout-note}\nFundamentally it's about allowing you to take this wrapping behavior for functions and to wrap wide swathes of functions in one fashion without having to rewrite a lot of user code or having to even perform a lot of turn on your library code.\n:::\n\nanother example when we want a function to run n-times:\n\n::: {#827cb88c .cell execution_count=17}\n``` {.python .cell-code}\nn = 2 # let's say 2 times\n\ndef ntimes(f):\n  def wrapper(*args, **kwargs):\n    for _ in range(n):\n      print('running {.__name__}'.format(f))\n      rv = f(*args, **kwargs)\n    return rv\n  return wrapper\n    \n@ntimes\ndef add(a, b=10):\n    return a + b\n\nadd(10, 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nrunning add\nrunning add\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=2}\n```\n30\n```\n:::\n:::\n\n\nwrapp `n` in to the function so `ntimes()` takes `n` instead of `f` as arg:\n\n::: {#5f7c8852 .cell execution_count=18}\n``` {.python .cell-code}\n# high order decorators\ndef ntimes(n):\n  def inner(f):\n    def wrapper(*args, **kwargs):\n      for _ in range(n):\n        print('running {.__name__}'.format(f))\n        rv = f(*args, **kwargs)\n      return rv\n    return wrapper\n  return inner\n    \n@ntimes(3)\ndef add(a, b=10):\n    return a + b\n\nadd(10, 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nrunning add\nrunning add\nrunning add\n```\n:::\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n30\n```\n:::\n:::\n\n\nThere is a very important core concept that is hidden in here which is what you might call the **closure object duality**. it's not something that we have time to look at in this session.\n\n# generator\n\nrecall what we've learned in previous section:\n\n- there are top-level syntax or function <--> and some underscore methods that implemented it.\n- if you have parentheses after something x() <--> implies `__call__` protocol implemented.\n\nwhat is different between these 2:\n\n::: {#0698ed3a .cell execution_count=19}\n``` {.python .cell-code}\ndef add1(x, y):\n  return x + y\n\n\nclass Adder:\n  def __call__(self, x, y):\n    return x + y \nadd2 = Adder()\n\nprint(add1(10, 20)) # 30\nprint(add2(10, 20)) # 20\ntype(add1) # <class 'function'>\ntype(add2) # <class '__main__.Adder'>\n```\n:::\n\n\nfunctionally there is not distinguish between `add1` and `add2`. `add1` is syntaxtically whole hell more easy to write. another diffence is if you want to add some *statefull behaviors*, we can easily modified the class:\n\n::: {#a5a98768 .cell execution_count=20}\n``` {.python .cell-code}\nclass Adder:\n  def __init__(self):\n    self.z = 0\n\n  def __call__(self, x, y):\n    self.z += 1\n    return x + y + self.z\n```\n:::\n\n\n[Äá»c thÃªm vá» [chuá»—i bÃ i nÃ y](https://magz.techover.io/2021/12/04/python-deep-dive-hieu-closures-decorators-va-cac-ung-dung-cua-chung-phan-1/) náº¿u tháº¥y confuse]{.aside}\n\nthere is one what to do with the Adder, another way to do with the function, what he hinted at this object **closure duality**.\n\nlet's think about a function that take a lot of time to do something, like loading the data from the database. we demo by a simple function `compute()`, which sleep 0.5 sec for each loop. the function only gives us the result once it completelt complete the loop, it will give us the entire result all at once. what if we care about the first? the first 3 values?\n\nthis is undesirable. this is wasteful both from the perspective of time & memory. let's think about it with the object model and rewrite under `Compute` class:\n\n::: {#583238e2 .cell execution_count=21}\n``` {.python .cell-code}\nfrom time import sleep\n\ndef compute()\n  rv = []\n  for i in range(100):\n    sleep(.5)\n    rv.append(i)\n  return rv\n\nclass Compute:\n  def __init__(self):\n    pass\n\n  def __call__(self):\n    rv = []\n    for i in range(100):\n      sleep(.5)\n      rv.append(i)\n    return rv\ncompute2 = Compute()\n```\n:::\n\n\nthe 2nd method: [[read more](https://realpython.com/python-callable-instances)]{.aside}\n\n- Retain state between calls (**stateful callables**)\n- Cache values that result from previous computations\n- Implement straightforward and convenient APIs\n\nif you want to access data during computaion, think of:\n\n```\nfor x in xs:\n  pass\n\nx1 = iter(xs)   ---> __iter__\nwhile True:\n  x = next(x1)  ---> __next__\n```\n\nand re-write the `Compute` like this:\n\n::: {#630e83a0 .cell execution_count=22}\n``` {.python .cell-code}\nclass Compute:\n  def __iter__(self):\n    self.last = 0\n    return self \n  \n  def __next__(self):\n    rv = self.last\n    self.last += 1\n    if self.last > 10:\n      raise StopIteration()\n    sleep(.5)\n    return rv\n\nfor val in Compute():\n  print(val)\n```\n:::\n\n\nnow, it:\n\n- takes 1 iteration to let you start using it;\n- takes no storage;\n- but looks ugly.\n\nand there is much simpler way to write a function that operate in such fashion, the **generator** syntax, it merely:\n\n::: {#8ff097c6 .cell execution_count=23}\n``` {.python .cell-code}\ndef compute()\n  for i in range(10):\n    sleep(.5)\n    yield i\n```\n:::\n\n\nits state is maintained internally. instead of eagerly computing the values, you give them to the user as the ask. let's look in the last example:\n\n::: {#cf92bb02 .cell execution_count=24}\n``` {.python .cell-code}\nclass Api:\n  def run_this_first():\n    first()\n  def run_this_second():\n    second()\n  def run_this_last():\n    lass()\n# in documentation you ask user to use those functions in order but no physically constraint you to not run like this:\nApi.run_this_last()\nApi.run_this_second()\nApi.run_this_first()\n```\n:::\n\n\nthe generator not only yield the result back, but also the control back to the caller. we can interleave our code with library code, controling them to run in order, that is conceptualization of how generators are built upon - co-routines.\n\nwe can either define execution function inside the class or use generator to control the sequence:\n\n::: {#2a98e5f2 .cell execution_count=25}\n``` {.python .cell-code}\n...\n  def doit():\n    first()\n    second()\n    last()\n... \n\n# or\n\ndef api()\n  first()\n  yield\n  second()\n  yield\n  last()\n```\n:::\n\n\n# context manager\n\nsetup & teardown ~ initial action and final action. we would often see pattern like:\n\n::: {#38b78af3 .cell execution_count=26}\n``` {.python .cell-code}\nwith open('ctx.py') as f:\n  pass\n```\n:::\n\n\nbeyond the file, it can be also sqllite\n\n::: {#3576f9c0 .cell execution_count=27}\n``` {.python .cell-code}\nfrom sqlite3 import connect\n\n# control the execution is executed when connection is open\nwith connect('test.db') as conn:\n  cur = conn.cursor()\n  cur.execute('create table points(x int, y int)')\n  cur.execute('insert into points(x, y) values (1, 1)')\n  cur.execute('insert into points(x, y) values (2, 1)')\n  cur.execute('insert into points(x, y) values (1, 2)')\n  for row in cur.execute('select sum(x * y) from points'):\n    print(row)\n  for row in cur.execute('select x, y from points'):\n    print(row)\n  cur.execute('drop table points')\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(5,)\n(1, 1)\n(2, 1)\n(1, 2)\n```\n:::\n:::\n\n\nnow we already control if connection is live to do something, we've not yet controlled inside the connection, the entry point and the exit point. now behind the scence\n\n```\nwith ctx() as x:\n  pass\n```\n\nwill look like the following:\n\n```\nx = ctx().__enter__\ntry\n  pass\nfinally:\n  x.__exit__\n```\n\nwe'll try to emplement this to our connection, we'll wrap it to a **temporary table behaviour**:\n\n::: {#2b7f6312 .cell execution_count=28}\n``` {.python .cell-code}\nfrom sqlite3 import connect\n\nclass Temporarytable:\n  def __init__(self, cur):\n    self.cur = cur\n  def __enter__(self):\n    print('__enter__')\n    self.cur.execute('create table points(x int, y int)')\n  def __exit__(self, *arg): # why need *arg\n    print('__exit__')\n    self.cur.execute('drop table points')\n\nwith connect('test.db') as conn:\n  cur = conn.cursor()\n  with Temporarytable(cur=cur):\n    cur.execute('insert into points(x, y) values (1, 1)')\n    cur.execute('insert into points(x, y) values (2, 1)')\n    cur.execute('insert into points(x, y) values (1, 2)')\n    for row in cur.execute('select sum(x * y) from points'):\n      print(row)\n    for row in cur.execute('select x, y from points'):\n      print(row)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n__enter__\n(5,)\n(1, 1)\n(2, 1)\n(1, 2)\n__exit__\n```\n:::\n:::\n\n\nnow can the exit run before the enter, no! they need to be run sequencely. it remind us about the **generator** to improve this:\n\n::: {#749b00d4 .cell execution_count=29}\n``` {.python .cell-code}\nfrom sqlite3 import connect\ndef temporarytable(cur):\n  print('created table')\n  cur.execute('create table points(x int, y int)')\n  yield\n  cur.execute('drop table points')\n  print('dropped table')\n\nclass Temporarytable:\n  def __init__(self, cur):\n    self.cur = cur\n  def __enter__(self):\n    self.gen = temporarytable(self.cur)\n    next(self.gen)\n  def __exit__(self, *arg):\n    next(self.gen, None)\n\nwith connect('test.db') as conn:\n  cur = conn.cursor()\n  with Temporarytable(cur=cur):\n    cur.execute('insert into points(x, y) values (1, 1)')\n    cur.execute('insert into points(x, y) values (2, 1)')\n    cur.execute('insert into points(x, y) values (1, 2)')\n    for row in cur.execute('select sum(x * y) from points'):\n      print(row)\n    for row in cur.execute('select x, y from points'):\n      print(row)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncreated table\n(5,)\n(1, 1)\n(2, 1)\n(1, 2)\ndropped table\n```\n:::\n:::\n\n\nenter and exit are already implemented in function `temporarytable` and cursor is implemented in the `connect()` call. now i would rewrite like this\n\n::: {#3007e670 .cell execution_count=30}\n``` {.python .cell-code}\nfrom sqlite3 import connect\n\nclass Temporarytable:\n  def __init__(self, gen):\n    self.gen = gen\n  def __call__(self, *args, **kwargs):\n    self.args, self.kwargs = args, kwargs\n    return self\n  def __enter__(self):\n    self.gen_instance = self.gen(*self.args, **self.kwargs)\n    next(self.gen_instance)\n  def __exit__(self, *arg):\n    next(self.gen_instance, None)\n\n@Temporarytable\ndef temporarytable(cur):\n  cur.execute('create table points(x int, y int)')\n  yield\n  cur.execute('drop table points')\n\n# temporarytable = Temporarytable(temporarytable)\n\nwith connect('test.db') as conn:\n  cur = conn.cursor()\n  with temporarytable(cur):\n    cur.execute('insert into points(x, y) values (1, 1)')\n    cur.execute('insert into points(x, y) values (2, 1)')\n    cur.execute('insert into points(x, y) values (1, 2)')\n    for row in cur.execute('select sum(x * y) from points'):\n      print(row)\n    for row in cur.execute('select x, y from points'):\n      print(row)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(5,)\n(1, 1)\n(2, 1)\n(1, 2)\n```\n:::\n:::\n\n\nall the stuff context manager above we do not need to write:\n\n::: {#f0ded331 .cell execution_count=31}\n``` {.python .cell-code}\nfrom sqlite3 import connect\nfrom contextlib import contextmanager\n\n@contextmanager\ndef temporarytable(cur):\n  cur.execute('create table points(x int, y int)')\n  try:\n    yield\n  finally:\n    cur.execute('drop table points')\n\n# temporarytable = Temporarytable(temporarytable)\n\nwith connect('test.db') as conn:\n  cur = conn.cursor()\n  with temporarytable(cur):\n    cur.execute('insert into points(x, y) values (1, 1)')\n    cur.execute('insert into points(x, y) values (2, 1)')\n    cur.execute('insert into points(x, y) values (1, 2)')\n    for row in cur.execute('select sum(x * y) from points'):\n      print(row)\n    for row in cur.execute('select x, y from points'):\n      print(row)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(5,)\n(1, 1)\n(2, 1)\n(1, 2)\n```\n:::\n:::\n\n\n# summary\n\nall combination of what we've learned in the last example:\n\n- a **context manager** is merely some piece of code that pairs set up actions and teardown actions. teardown occurs only if set up occurs\n- a **generator** is merely some form of syntax that allows us to do things like enforce sequencing and interleaving notice the\n\nfinally we need something to adapt the generator to this data model that we looked at at the very beginning. we have these underscore methods and we have to find some way to take how the generator works and fit it into those underscore methods. one of the things we need to do in order to do that is we need to take this generator object to wrap it in some fashion that wrapping is part of the core of how Python works it's easy to dynamics and construct functions\n\n- there does happen to be a feature called **decorators** that allows us a nice convenient syntax for doing that exactly.\n\n:::{.callout-tip}\ncriteria of Python expert code:\n\n- expert level code is not code that uses every single feature;\n- it's in fact not code that even uses that many features of Python;\n- it's code that has a certain clarity to where and when a feature should be used; \n- it's code that doesn't waste the time of the person who's writing it because they say to themselves I have this pattern Python has this mechanism I fit them together\nand everything just seamlessly and and very smoothly works;\n- it's code that doesn't have a lot of additional mechanisms associated with it it doesn't have people creating their own protocols it doesn't have people creating their\nown frameworks where the language itself provides the core pieces that you need and you merely have to understand what those core pieces are what they need and\nhow to assemble them.\n:::\n\n# futher reading\n\n1. [Python data model](https://docs.python.org/3/reference/datamodel.html)\n2. [Python metaclass `__new__`](https://www.geeksforgeeks.org/python-metaclass-__new__-method/)\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}