{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **N-gram MLE Playground**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsmoothed MLE on a character-level language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "\n",
    "def train_char_level_lm(data: list, block_size: int = 4) -> dict:\n",
    "    dict = defaultdict(Counter)\n",
    "    padding = \"~\" * block_size\n",
    "    data = padding + data\n",
    "    # counting\n",
    "    for i in range(len(data) - block_size):\n",
    "        input, output = data[i : i + block_size], data[i + block_size]\n",
    "        dict[input][output] += 1\n",
    "\n",
    "    # normalization\n",
    "    def normalize(counter: Counter) -> list:\n",
    "        size = float(sum(counter.values()))\n",
    "        return [(c, cnt / size) for c, cnt in counter.items()]\n",
    "\n",
    "    return {input: normalize(output) for input, output in dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the Andreg Karpathy's **Shakepears**'s dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2025-01-23 13:20:59--  https://raw.githubusercontent.com/karpathy/char-rnn/refs/heads/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: 'input.txt'\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  4%  541K 2s\n",
      "    50K .......... .......... .......... .......... ..........  9%  966K 1s\n",
      "   100K .......... .......... .......... .......... .......... 13% 2.52M 1s\n",
      "   150K .......... .......... .......... .......... .......... 18% 3.70M 1s\n",
      "   200K .......... .......... .......... .......... .......... 22% 1.04M 1s\n",
      "   250K .......... .......... .......... .......... .......... 27% 4.68M 1s\n",
      "   300K .......... .......... .......... .......... .......... 32% 1.94M 1s\n",
      "   350K .......... .......... .......... .......... .......... 36%  104M 0s\n",
      "   400K .......... .......... .......... .......... .......... 41%  171M 0s\n",
      "   450K .......... .......... .......... .......... .......... 45% 1.37M 0s\n",
      "   500K .......... .......... .......... .......... .......... 50% 10.5M 0s\n",
      "   550K .......... .......... .......... .......... .......... 55% 8.80M 0s\n",
      "   600K .......... .......... .......... .......... .......... 59% 9.48M 0s\n",
      "   650K .......... .......... .......... .......... .......... 64% 9.09M 0s\n",
      "   700K .......... .......... .......... .......... .......... 68% 3.44M 0s\n",
      "   750K .......... .......... .......... .......... .......... 73% 17.1M 0s\n",
      "   800K .......... .......... .......... .......... .......... 78% 14.1M 0s\n",
      "   850K .......... .......... .......... .......... .......... 82% 14.0M 0s\n",
      "   900K .......... .......... .......... .......... .......... 87% 11.5M 0s\n",
      "   950K .......... .......... .......... .......... .......... 91% 4.03M 0s\n",
      "  1000K .......... .......... .......... .......... .......... 96% 4.33M 0s\n",
      "  1050K .......... .......... .......... .........            100% 12.1M=0.4s\n",
      "\n",
      "2025-01-23 13:21:00 (2.86 MB/s) - 'input.txt' saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/refs/heads/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load **data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115394"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"input.txt\", \"r\") as f:\n",
    "    data = f.read()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the **model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_char_level_lm(data=data, block_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 1.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"Hell\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('l', 0.5), ('t', 0.5)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"tua \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 0.5578231292517006),\n",
       " ('u', 0.034013605442176874),\n",
       " (';', 0.013605442176870748),\n",
       " ('l', 0.10204081632653061),\n",
       " ('.', 0.06802721088435375),\n",
       " (',', 0.061224489795918366),\n",
       " (':', 0.013605442176870748),\n",
       " ('s', 0.08843537414965986),\n",
       " (\"'\", 0.006802721088435374),\n",
       " ('i', 0.013605442176870748),\n",
       " ('e', 0.006802721088435374),\n",
       " ('\\n', 0.027210884353741496),\n",
       " ('!', 0.006802721088435374)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[\"sing\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random\n",
    "\n",
    "def character_sampling(\n",
    "    model: dict, \n",
    "    input: str, \n",
    "    block_size: int\n",
    "    ) -> str:\n",
    "    \n",
    "    input = input[-block_size:]\n",
    "    distribution = model[input]\n",
    "    \n",
    "    x = random()\n",
    "    for char, pct in distribution:\n",
    "        x -= pct\n",
    "        if x <= 0: \n",
    "            return char\n",
    "        \n",
    "def text_sampling(\n",
    "    model: dict, \n",
    "    block_size: int, \n",
    "    n_char: int = 1_000\n",
    "    ) -> str:\n",
    "    \n",
    "    input = \"~\" * block_size\n",
    "    output = []\n",
    "    \n",
    "    for i in range(n_char):\n",
    "        # sampling a character\n",
    "        char = character_sampling(model, input=input, block_size=block_size)\n",
    "        # update input\n",
    "        input = input[-block_size:] + char\n",
    "        # append to output\n",
    "        output.append(char)\n",
    "        \n",
    "    return \"\".join(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with different `block_size`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `block_size` = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fir: I hisbuthe que's olikenswady ou colors nin,\n",
      "And they we shat? bou nathe the loon.\n",
      "If yours.\n",
      "\n",
      "As de thy deady ploo hingell coll ithip ear witheande upte.\n",
      "\n",
      "Go, alt thish\n",
      "Thimplard's I he of yourds the a de girome emen I we safeaks!\n",
      "\n",
      "Wout therst, tis th! forming yousuniour IV:\n",
      "For thim!\n",
      "\n",
      "Nay, youlneave by grans your burld thrive Lors yourpent shily\n",
      "in anglaing swerrield seen dese afecand cle romench ar mand Ser\n",
      "And be upowead bunse the come then ty of fand thee day\n",
      "Whalif hok'd womps foebeaver er.\n",
      "Wrall whour ciat thy on\n",
      "Hard cand him:\n",
      "Whased wice, yould sword now's morseed. Wher\n",
      "ANUS:\n",
      "Shours st:\n",
      "Youghs ou mither.\n",
      "Agazen I hand theith hey,\n",
      "And faunest le;\n",
      "Anded wer bow no musirse;\n",
      "As que.\n",
      "\n",
      "CORIANDA:\n",
      "MARD I flaus th ye.\n",
      "\n",
      "My sorm ante hatedneelf cancer them shin my ine be so, and my goleappy heardo das not win crain he'st thrit wert\n",
      "Geons beitherved hicius nown. I hill ling the sheneven of wat wit\n",
      "I an to of Go vid, my hally corst plat he thead play a us nothincent,\n",
      "To haven an, th:\n",
      "So\n"
     ]
    }
   ],
   "source": [
    "model_2gram = train_char_level_lm(data=data, block_size=2)\n",
    "print(text_sampling(model=model_2gram,block_size=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `block_size` = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First: beat,\n",
      "And here is name?\n",
      "Was evenge on the city\n",
      "And somen we know have give as I am fair!\n",
      "\n",
      "PAULINA:\n",
      "My lord,\n",
      "For the this i' the devils,\n",
      "And joys my head:\n",
      "Good and say, good not some possess caps and all not now I am I shall me subject not,\n",
      "That what not stock my heaven, letterly, a son, Aufidius!\n",
      "\n",
      "LEONTES:\n",
      "Farewell me, Corioli having tongue\n",
      "Fault order grave him our best to-day:\n",
      "In all mother, naked thou are hope:\n",
      "Thinks in thence: letters on his ruin's lady,\n",
      "But, so despair!\n",
      "\n",
      "PRINCENTIO:\n",
      "This count from the advantagems\n",
      "Are some tend send man arms\n",
      "Upon us.\n",
      "\n",
      "GRUMIO:\n",
      "Will the highness call take the me in abused truments then I belier made this say\n",
      "the fill freely\n",
      "Yielder; thou be limit. You some but does, the conventure's day your arrant\n",
      "An old entable villain, hands\n",
      "Till I know upon this most:\n",
      "Here's have\n",
      "you from peppery?\n",
      "\n",
      "Proclaim'd three ill-vex'd.\n",
      "\n",
      "MENENIUS:\n",
      "No; it no dignified\n",
      "Of ever hearth,\n",
      "And was back of a qual scene your say in then you slave, uncles,\n",
      "As if he see ill n\n"
     ]
    }
   ],
   "source": [
    "model_4gram = train_char_level_lm(data=data, block_size=4)\n",
    "print(text_sampling(model=model_4gram,block_size=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `block_size` = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "You have no such mercy which, being so\n",
      "capital? Tell me here: murderer:\n",
      "No;\n",
      "For my patience taken: 'shrew me, but a man for stirring up the Montague,\n",
      "Resolved mates!\n",
      "Are you go:\n",
      "I think so, which you at the gaoler, the this\n",
      "cuff was but a very pink of it?\n",
      "\n",
      "DUKE OF YORK:\n",
      "Come, my sovereign,\n",
      "You said so. Farewell, go, poor Rome,\n",
      "And neither shalt do not taken your ladyship?\n",
      "\n",
      "ANGELO:\n",
      "And more honour two notorious Prince Edward dares, and my desert!\n",
      "\n",
      "CORIOLANUS:\n",
      "Which out of him as well as reverse an say 'silver sound\n",
      "The cruel with smiles;\n",
      "And heard theirs, their hats.\n",
      "But leave\n",
      "to think no less.\n",
      "\n",
      "FLORIZEL:\n",
      "What dread\n",
      "These and reigns. I never reign and these heads butts me about! Believe your grace.\n",
      "\n",
      "First Huntsman:\n",
      "It would succeed that means\n",
      "To make my ring.\n",
      "\n",
      "First Servingman:\n",
      "How now! who comes, offer we refuse thy foot.\n",
      "\n",
      "CORIOLANUS:\n",
      "What shall die.\n",
      "\n",
      "KING RICHARD III:\n",
      "Thanks, gentleman, and they so?\n",
      "\n",
      "BUCKINGHAM:\n",
      "Upon my gracious lord.\n",
      "\n",
      "PRINCE EDWARD:\n",
      "Now breaks this dam\n"
     ]
    }
   ],
   "source": [
    "model_7gram = train_char_level_lm(data=data, block_size=7)\n",
    "print(text_sampling(model=model_7gram,block_size=7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `block_size` = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Clubs, bills, and partisans, in hands as old,\n",
      "Canker'd with that odds he weighs King Richard let me speak:\n",
      "As I do know;\n",
      "And all my followers.\n",
      "\n",
      "MONTAGUE:\n",
      "Thou villain, and soon persuade\n",
      "Both him and her, sir: what have we here! Mercy on 's, a barne a very\n",
      "pretty barne! A boy or a child, will go by thy direction:\n",
      "If your more ponderous and settled project\n",
      "May suffer alteration, finding\n",
      "Myself thus alter'd from the whom, I see,\n",
      "There's more work.\n",
      "What is the way to lay the city but the people,\n",
      "As if you were not I a little for my counsel,\n",
      "Which must be even in our government.\n",
      "You thus have marked me.\n",
      "\n",
      "HASTINGS:\n",
      "Sound trumpets sound\n",
      "While we devise him.\n",
      "\n",
      "COMINIUS:\n",
      "I have not yet made doubt but Rome was ready\n",
      "To answer us.\n",
      "\n",
      "AUFIDIUS:\n",
      "Whence come you? what's your will, sir,\n",
      "No remedy.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "Hold; get you gone:\n",
      "You have taken treasure of the foe?\n",
      "\n",
      "NORFOLK:\n",
      "My lord,\n",
      "Fear none of them\n",
      "with his charity, obedience fails\n",
      "To the greater poll, and in his full tilth and hus\n"
     ]
    }
   ],
   "source": [
    "model_2gram = train_char_level_lm(data=data, block_size=10)\n",
    "print(text_sampling(model=model_2gram,block_size=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "1. Andrej Karpathy's post: <https://karpathy.github.io/2015/05/21/rnn-effectiveness/>;\n",
    "2. Yoav Goldberg on Andrej post: <https://nbviewer.org/gist/yoavg/d76121dfde2618422139>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
