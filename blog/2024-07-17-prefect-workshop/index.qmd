---
title: "A Prefect Workshop"
description: "by Dr. Adam Hill in PyData London 2024"
author:
  - name: "Tuan Le Khac"
    url: https://lktuan.github.io/
categories: [python, pydata, prefect] 
date: 07-17-2024
date-modified: 07-17-2024
image: adam_hill.png
code-tools: true
code-fold: show
code-annotations: hover
draft: false
css: html/styles.scss
fig-cap-location: bottom
editor: visual
format:
  html:
    code-overflow: wrap
---

üéû Video source: [Dr. Adam Hill - Empower Your Projects with Prefect's Pipeline Magic | PyData London 2024](https://www.youtube.com/watch?v=yIDBsHwTaa8&list=PLGVZCDnMOq0rrhYTNedKKuJ9716fEaAdK&index=4)

‚õè Github repo: <https://github.com/Cadarn/PyData-Prefect-Workshop>

# goals

by end of this session you will:

- understand what Prefect is;
- build and execute tasks and flows;
- have schedules flow using deployment;
- have a grasp what else can be done;
- have some fun.

# prefect overview

just simple as using jupyter notebook, you only need to use decorators (`@task` and `@flow`) to designate functions as **task** for **flow**. you need to breakdown your "notebook" into "code chunks" and organize to get them done.

```{python}
#| eval: false 

from prefect import task, flow

@task
def my_task():
  print("hello, i am a task!")

@flow
def my_flow():
  my_task()
```

# jump to the workshop

clone the repo, have docker compose up and running. then explore `http://localhost:8000/get_tweet`, this is shown which i have yet no idea:

```json
{
  "tweet_id": 570306133677760500,
  "airline_sentiment": "neutral",
  "airline_sentiment_confidence": 1,
  "airline": "Virgin America",
  "name": "cairdin",
  "text": "@VirginAmerica What @dhepburn said.",
  "retweet_count": 0,
  "tweet_timestamp": "2015-02-24T11:35:52-08:00",
  "tweet_coord": -1,
  "loop": 1
}
```

the first thing you need to do is telling where the Prefect API is gonna live. currently it runs on free tier of the their cloud server (?) and now we config it to run in the localhost (?):

```bash
prefect config set PREFECT_API_URL="http://127.0.0.1:4200/api"
```

then we gonna reset the database, do some config then can start the server. please note that if you are using window, you need to add `Scripts` variable to environment variables also, the value of the path can be found when you install Prefect by `pip`:

```bash
prefect server database reset -y
prefect config set PREFECT_API_DATABASE_CONNECTION_URL="postgresql+asyncpg://postgres:password@localhost:5432/prefect_server"
prefect config view --show-sources
prefect server start
```

below is my initial dashboard, there is nothing!

:::{layout-ncol="1"}
![Prefect Dashboard](initial_prefect_server.png)
:::

## e01 my first flow

the basic component of prefect is `task` and `flow`. these are decorators to funtions we want to run. we can name and log easily:

```{.python filename="e01.py"}
from prefect import task, flow


@task(name="Addition operator")  # this task will successfully run
def add(a, b):
    return a + b


@task(name="Squaring operator")  # this task will fail
def square_num(num):
    if True:
        raise ValueError
    return num ** 2


@flow(log_prints=True,
      name="Add and Square",
      description="My first simple flow")
def add_and_square(a: int = 2, b: int = 3):
    add_result = add(a, b)
    square_result = square_num(add_result)
    print(f"({a} + {b}) squared = {square_result}")


if __name__ == "__main__":
    add_and_square(4, 8)
    
```

## e02a sentiment pipeline v1

## e02b sentiment pipeline v2

## e03a kafka tweet publisher

## e03b kafka tweet deployment

## e04 sentiment pipeline v3

# further reading

1. [Prefect vs Airflow on Reddit](https://www.reddit.com/r/dataengineering/comments/oqbiiu/airflow_vs_prefect/)

B√¨nh lu·∫≠n b·ªüi **u/alexisprince**:

> T√¥i ƒëang s·ª≠ d·ª•ng song song Airflow v√† Prefect (A cho scheduling, P cho execution), P ƒë∆∞·ª£c s·ª≠ d·ª•ng khi y√™u c·∫ßu v·ªÅ hi·ªáu nƒÉng t√≠nh to√°n v√† ph·∫ßn scheduler c·ªßa A v·∫´n ch∆∞a th·ªÉ b·ªã thay th·∫ø.
> 
> L·ª£i th·∫ø c·ªßa A l√† ƒë√£ qu√° ph·ªï bi·∫øn, d·ªÖ t√¨m h∆∞·ªõng d·∫´n, d·ªÖ tuy·ªÉn ng∆∞·ªùi cho chuy√™n m√¥n. Y·∫øu ƒëi·ªÉm l√† A ƒë√£ qu√° c≈©, kh√¥ng c√≤n ph√π h·ª£p cho dynamic workflow v√† modern data env. H∆°n n·ªØa A lu√¥n best fit khi s·ª≠ d·ª•ng chung v·ªõi Astronomer, ngo√†i ra kh√° kh√≥ d√πng.
> 
> P hi·ªán ƒë·∫°i h∆°n, cung c·∫•p nhi·ªÅu modern execution models, DAG ƒë∆∞·ª£c x√°c ƒë·ªãnh t·∫°i runtime do ƒë√≥ dynamic h∆°n.
> 
> Prefer P h∆°n, better modularization of code.

B√¨nh lu·∫≠n b·ªüi **u/ChrisHC05**:

> Tao ƒë√£ ƒë√°nh gi√° Airflow, Dagster, Argo v√† Prefect m·∫•y th√°ng nay.
> 
> Airflow th√¨ ƒë√£ gi√†, tuy nhi√™n t√†i li·ªáu, h∆∞·ªõng d·∫´n r·∫•t phong ph√∫.
> 
> Dagster c√≥ v·∫ª g·∫∑p nhi·ªÅu v·∫•n ƒë·ªÅ v·ªõi Production.
> 
> Prefect c√≥ c·ªông ƒë·ªìng ph√°t tri·ªÉn, support, s·ª≠a l·ªói active.
> 
> V·∫≠y n√™n t√¥i ch·ªâ ƒë√°nh gi√° cao hai th·∫±ng Argo v√† Prefect. Argo kh√°c bi·ªát m·ªôt c√°ch m·∫°nh m·∫Ω, config ƒë∆∞·ª£c vi·∫øt d∆∞·ªõi d·∫°ng YAML, ch·∫°y tr√™n c·ª•m Kubernetes, v√† vi·ªác vi·∫øt DAG kh√¥ng ph·ª• thu·ªôc v√†o m·ªôt ng√¥n ng·ªØ l·∫≠p tr√¨nh n√†o. Argo (t·∫°i th·ªùi ƒëi·ªÉm ƒë√≥) c≈©ng ƒëang ph√°t tri·ªÉn m·ªôt module ki·ªÉu event listening, from outside, nh∆∞ Sensor c·ªßa Airflow, th·ª© m√† Prefect thi·∫øu (workaround l√† call Prefect GraphQL-API).
> 
> N·∫øu ƒë√£ c√≥ s·∫µn infra l√† K8S, khuy·∫øn ngh·ªã Argo, kh√¥ng ch·ªâ l√† orchestration m√† c√≤n l√† m·ªôt h·ªá sinh th√°i support t·ª´ event responding t·ªõi CI/CD. Nh∆∞ng learning curve th√¨ steep nh√©. N√≥ c√≥ nhi·ªÅu ti·ªÅm nƒÉng v√¨ gi·ªù th√¨ ph·∫ßn m·ªÅm n√†o c≈©ng c·∫ßn dockerized c·∫£, t√≠nh tr·ª´u t∆∞·ª£ng cao h∆°n. "And IT in general is all about abstraction to make complicated things easier."
> 
> V·∫≠y n√™n:
> 
> - N·∫øu c√≥ s·∫µn c·ª•m K8S: d√πng Argo
> - N·∫øu kh√¥ng: d√πng Prefect

2. [Airflow Vs. Prefect: Full Breakdown! by The Data Guy](https://www.youtube.com/watch?v=XrZegcm1ftw)
3. [Adam Hill's blog](https://www.horsewithapointyhat.com/posts/being-a-data-scientist-in-a-post-truth-world/)