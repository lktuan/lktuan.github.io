{
"0s": "Sunday smile and keep",
"6s": "on even in the of the night the words are ringing in your mind just give them",
"15s": "your",
"20s": "[Music] smile Blood Cuz you're so tired of",
"26s": "running your five ws only told them you",
"39s": "at",
"46s": "only at",
"52s": "all if Hearts on Fire and they're showing you a one way Sun just give them",
"1:01": "your Sunday smile and keep them",
"1:07": "on even in the dead of the night the words are ringing in your mind just give",
"1:16": "them your Sunday smile and keep them mov",
"1:23": "on you better not look down you better not look down you see a shadow you see a",
"1:29": "shadow don't let the feeling",
"1:38": "go you better I look down you better I look down you see a shadow you see a",
"1:53": "shadow sing n n n",
"2:04": "all right hello everyone it is my pleasure to announce the next speaker uh",
"2:10": "Daniel S Johnny and uh I'm very curious to hear what he has to say about cause",
"2:17": "of effect estimation because I I love learning uh from yeah lessons uh uh from",
"2:24": "people in the field so give him a big round of applause",
"2:28": "[Applause]",
"2:33": "good morning everyone thanks for being here um as mentioned I'm going to be",
"2:37": "telling you about causal effect estimation I'm I'm a data scientist and",
"2:42": "analytics translator in finance Banking and we are trying to use",
"2:49": "these basically tools and techniques from causal inference to answer business",
"2:54": "questions however the Practical situation that you have is",
"3:00": "quite different than the beautiful data set that you get with n's treatment and",
"3:04": "control and you can do sometimes with those data sets trying many algorithms",
"3:10": "and see what are the basically effect happily we had very interesting",
"3:17": "talks in Pata 24 already on different aspect",
"3:23": "of causal inference what I'm going to be touching upon is a little bit over away",
"3:30": "from that theory and how situation would look like in practice",
"3:36": "so by no means the things that I'm mentioning would be basically a",
"3:42": "recommendation just my lessons learn and my experience from the journey that I",
"3:47": "had and the outline of the talk I'm going to",
"3:52": "be basically just providing what are the practical use cases we're trying to",
"3:56": "answer with these tools and techniques what are the standard Solutions and and",
"4:00": "where are they failing and how they might not feed completely into practice",
"4:04": "the challenges and I will also conclude the talk with some",
"4:09": "example introduction about causal inference as you know um it goes further",
"4:15": "than just predicting right so if you could basically have the the czzle map",
"4:22": "and and do effect estimation you can go even further to influencing outcome not",
"4:26": "just predict it but also control or influence it",
"4:30": "the applications that are out there are manifold most basic one is effect",
"4:36": "estimation you always basically take certain action and you want to see",
"4:40": "what's the outcome it's called effect estimation in literature however you",
"4:44": "also have other use cases like root cause analysis that you want to see",
"4:49": "basically which factor uh impacts more your outcome or like causes more the",
"4:55": "outcome or you have also that vative analysis that looks into the contrafact",
"4:59": "ual situation and so on but to in today's talk I'm going to be touching",
"5:03": "upon two of the use cases that we are basically looking at in practice one of",
"5:08": "them is the uh one of them is the marketing",
"5:13": "campaigns that we uh basically send to our clients and we want to see how",
"5:19": "basically clients are reacting to these marketing campaigns based on different",
"5:22": "kpis and also if it would impact our basically uh business",
"5:27": "kpis the other thing is sometimes Financial",
"5:34": "Services has some services that are basically for",
"5:40": "free right we provide Financial consultation to our clients but we want",
"5:45": "to know if these are actually bringing value to our clients or to",
"5:52": "us I will start with the golden standard solution uh as you have heard um AB",
"5:57": "testing is the golden standard solution when you want to look into basically",
"6:02": "estimating effect of course it's not the only experimental design but it's one of",
"6:07": "them in this setting we want to look into when we are sending email to our",
"6:12": "clients and with certain content when we desire is that they either bu basically",
"6:19": "buy a certain product for example and we want to see if that basically uh",
"6:23": "basically this email is changing anything so in these situations if you",
"6:28": "want to go the standard golden standard you you randomly divide your population",
"6:32": "to a group that receives the campaign email campaign and a group that does not",
"6:37": "and then in this situation if you do a proper randomized experiment you have",
"6:41": "balance of covariates and then whatever impact you see from these the treatment",
"6:46": "to your outcome which is basically Association is also causation however",
"6:51": "this is not going to hold in practice sometimes in practice they forget to do",
"6:55": "this actually they might not be data scientists or have not knowledge about",
"6:59": "data science when they're doing these sending these marketing campaigns in",
"7:02": "practice the marketeers so either they might forget or sometimes they know but",
"7:07": "it's either expensive or basically messes up their business if they want to",
"7:12": "work on like that one of these examples is like in in finance when you are",
"7:17": "basically want to know what is the impact of a credit line to customer",
"7:20": "churn if you provide a good credit line to some clients that just to keep them",
"7:26": "it could cause the risk to the Financial Risk to the bank right in sometime",
"7:30": "situations so it's not practical in another situation you could assume that",
"7:35": "it could also be unethical and you can see it like when you want to see the",
"7:39": "impact of for example alcohol on on pregnancy so it's it's it's it's not",
"7:44": "possible Right you also have situation that the clients uh or like subjects",
"7:49": "might not comply uh with whatever you're trying to basically uh you send an email",
"7:54": "to someone but also partner of the the the the client also sees the email so",
"7:59": "and of course sometimes there are small data to do that so what is different in",
"8:04": "practice this is the ideal case in in theory what you basically uh want to",
"8:10": "have you are simultaneously contacting a group of clients with certain email at",
"8:16": "the same time sometimes you have control group and sorry most of the time you",
"8:22": "have control group however it could be a randomized control group but also could",
"8:25": "not be a randomized so both is fine but in practice",
"8:30": "ice you're not going to be simultaneously contacting these clients",
"8:35": "because for example how things are practice is you have a system based on",
"8:39": "the eligibility criteria that the campaign has like the clients which have",
"8:44": "certain age if they have a certain product and based on this send out the",
"8:48": "campaign you might be targeting on weekly basis certain group of your",
"8:52": "clients so not having like let's suddenly in one point of time contacting",
"8:59": "50,000 or 10,000 clients but on weekly basis certain group of clients you don't",
"9:04": "have any control because you have just reached out to certain clients so you",
"9:08": "have targeted 10,000 clients while you have a customer base of 2 million good",
"9:12": "luck finding the control in that in the two million that would be comparable to",
"9:16": "your 10,000 clients that you have reached out and of course there's no",
"9:20": "Randomness what I'm going to be basically walking you through this the",
"9:24": "the the following slides is I'm going to be building up how we can address these",
"9:28": "uh basically the challenges one by one I start with",
"9:33": "Randomness and then how to define and shape a control group that's reasonable",
"9:37": "is a good control and of course what to do when there is no simultaneous reach",
"9:45": "out when we are doing randomized experiment we have the",
"9:51": "luxury of decoupling the features impact on the treatment because",
"9:58": "C we are randomly putting clients into a group a and group b or control and",
"10:04": "treatment and you have a balanced of age sex and all of those co-variates that",
"10:09": "you can think about in both group however if that's not done based on a",
"10:14": "randomized experiments you always get some Arrow from X to T that means the",
"10:19": "relationship impacts the treatment you have in one group probably more older",
"10:25": "maybe clients or more female or male and of of course the age also naturally",
"10:32": "impacts probably your conversion because you know that uh clients who are younger",
"10:37": "probably would be willing to use email more and then they would be more online",
"10:43": "friendly so effect estimation looks at the effect of t on y given how we can",
"10:50": "account for different variables in the X and there are of course two School of",
"10:55": "thoughts one of them is potential outcome comes from uh from statistics",
"10:59": "and their other school of thought is basically a structural CA model and they",
"11:05": "require basically a bief about the C graph and what you see on the right is",
"11:10": "actually the coal graph so in Po in potential outcome you have a population",
"11:15": "you have uh basically you want to reach out to these uh population with a group",
"11:19": "of them with the email and another group you don't send email if you're in a",
"11:23": "parallel universe",
"11:26": "then the average conver verion in the group that received the email minus the",
"11:32": "average group that did not receive the email is your basically answer right",
"11:37": "then you have the answer to your czzle question but unfortunately this is not",
"11:42": "possible this the fundamental problem of czzle inference you can't see outcome",
"11:47": "for both group at the same time so then what you're going to be doing you're",
"11:52": "going to slice that population you're going to treat one C population with an",
"11:57": "email and you have another slice that has not been basically uh targeted and",
"12:03": "then in this case case you have a selection you're having you're looking",
"12:06": "at Association but when is this Association",
"12:10": "causation to quickly look at it if you have exchangeability what does that ex",
"12:15": "what what does exchangeability mean in this",
"12:17": "context if you do not reach to both of your subgroup of the clients you have",
"12:23": "same conversion no email both group have two out of 10 you sending email doesn't",
"12:29": "matter to which both group gives you for examp for example four out of 10 that's",
"12:33": "exchangeability you want to have the positivity",
"12:37": "condition what does that mean that means you want to have overlap in your coarer",
"12:41": "distributions if your control has some basically clients between 80 to 90 you",
"12:48": "want to also have at least some also in your control group if there's that's the",
"12:52": "case in treatment you want to have no interference that means if you're",
"12:55": "sending email to certain group of your clients the other group that was",
"12:59": "isolated did not receive this you want to have consistency that the slice of",
"13:05": "the population that you reach out for example with sport for example email a",
"13:11": "sport product whatever you don't Target them also for another a topic like uh",
"13:16": "like digital products whatever then you have basically",
"13:21": "interference these are the assumptions that you need to hold so",
"13:27": "you could do basically you can argue cause Association is causation and if",
"13:32": "you have randomized experiment you get the first two for free that's fantastic",
"13:38": "but again we are not in there if the there was a randomized experiment you",
"13:44": "don't have the relationship from the X to T but because there's no",
"13:47": "randomization you have that relationship as I told",
"13:53": "you because of this arrow that you see from X to T your causal Association that",
"13:58": "runs from T to Y the t is treatment Y is outcome",
"14:03": "conversion could also be influenced via an confounding Association that would",
"14:08": "pollute your causal Association why consider X as age and you have in one",
"14:14": "group clients of between 80 to 90 mostly and another one 20 to 30 and because of",
"14:22": "this you are kind of opening a backd door path from X that runs through from",
"14:27": "T that runs through X and goes to y so this not only impacts the basically",
"14:33": "it also impacts the wine and you want to fix this you want to get rid of that",
"14:37": "Arrow from X to Y how would potential outcome treat this is as follow they",
"14:43": "would try to find the treatment assignment mechanism that fits the x2t",
"14:48": "and based on the propensity model try to correct for that so you basically fit a",
"14:55": "ordinary list Square model to your outcome which is basically the treatment",
"14:59": "and X are the features you get probabilities based on certain feature",
"15:02": "you have a probability of being in that group then you inverse that and applied",
"15:07": "into your outcome so now you're mimicking randomization great right so",
"15:12": "we managed to address that randomization part and then you see Association is",
"15:16": "causation in this case if all the other basically uh constraint and let's say",
"15:22": "sorry assumptions are hold we're going to be using this in our",
"15:27": "example so uh the p is very simple for doing this in practice you don't need",
"15:31": "any sophisticated tool only ordinary listed square and you use this",
"15:36": "probabilities and you inverse them and you work with those inverse",
"15:39": "probabilities to rev your outcomes to see how this could work in",
"15:45": "practice there's also the other school of thought that's the structural causal",
"15:51": "models um that's a little bit",
"15:56": "different it would basic but works on a based basically on the same concept and",
"16:03": "normally when you apply these two you shouldn't get uh very contr you",
"16:07": "shouldn't get a different result so basically they you should be able to",
"16:10": "retrieve the same uh effect estimation and there's of course overlap",
"16:17": "but they're looking at more uh basically uh they're looking at a more complete",
"16:22": "picture because with potential outcomes we looked at uh this basically causal",
"16:28": "graph but which of course we have to always account for the confounder X for",
"16:33": "example age that I already told you and the average treatment effect in",
"16:38": "this context is always the coefficient of T right so when you fit again so or",
"16:44": "this the square your outcome a BX but of course the x is only going to be",
"16:49": "Compounders because you have to avoid including or conditioning on variables",
"16:56": "that block the flow of causation from T to Y so if you look at this left example",
"17:02": "you have treatment let's assume you're playing music you have y outcome",
"17:06": "happiness and you have a mediator memory So based on a music you have played for",
"17:10": "someone it triggers a memory and they become",
"17:13": "happy you should not basically if you assume that memory is a variable that",
"17:18": "you can quantify and measure you should not account for it in your model because",
"17:23": "then you're blocking the association that uh causal Association that runs",
"17:27": "through that mediator also in the non- Cazal you also have sometimes non- Cazal",
"17:33": "associations that basically both T and Y are impacting something consider dance",
"17:38": "when you're playing in music and um as a result of this music Somebody starts",
"17:43": "dancing but of course because they are happy they could also start dancing if",
"17:48": "you condition on the dance for example in this situation collider you're",
"17:53": "introducing a bias so these are the theory um the takeaways and what I I",
"17:59": "just told you I'm going to be quickly taking you a little bit now to some of",
"18:03": "those practicalities that I discussed one of them is kpi when you",
"18:08": "want to basically do an effect estimation it's important to look at",
"18:12": "what do you want to show that is changing to your basically business your",
"18:16": "stakeholders right the team so how the effect is propagating right you send an",
"18:21": "email to clients they open the email probably",
"18:24": "they see it and that could take for example one week",
"18:29": "after that they might uh basically do a little bit of orientation they might uh",
"18:34": "do research they might contact this here there and they probably some of them not",
"18:39": "all of course going to take the product right so of course let's assume that",
"18:44": "this is a midterm kpi that would take within within two to eight weeks and",
"18:49": "then of course if the client starts using the product of course this is not",
"18:53": "going to hold probably for many businesses it depends some businesses",
"18:57": "when you acquire a product basically that means the revenue stream is going",
"19:00": "to be coming in but in some other businesses if you acquire a product you",
"19:04": "need to use the product so a revenue stream would follow and let's assume",
"19:09": "also like then you also have data availability things and and and the",
"19:13": "long-term kpi could be impacted within 8 to 16 week so now you see the effect is",
"19:19": "going from your treatment all the way to all these kpis throughout time and you",
"19:25": "also need to take into account the variables that impacting the treatment",
"19:30": "and outcome and these are of different",
"19:33": "nature I told you it could be a mediator could be a confounder could be a",
"19:37": "collider the more you go to the right side of the spectrum you need to account",
"19:42": "to more features if you're basically taking email scene let's say click",
"19:46": "through rate that's something like would be used sometimes by",
"19:50": "business your your life is probably easier than going to the product because",
"19:55": "then you also need to account for featur is related to the product and all the",
"20:00": "way if you go to the revenue then you need to also account for features that",
"20:03": "impact money I don't know inflation and and so many things that",
"20:08": "could basically impact that so this is something in practice that you might",
"20:14": "need to pay attention when you want to do CLE inference so you want to promise",
"20:20": "an effect estimation at which kpi to your stakeholders because what you see",
"20:25": "there this could be a little bit complicated right if you have txy but",
"20:30": "then also the Y's that are passing the causal effect throughout",
"20:36": "time to another kpi and of course the other features that might play a role in",
"20:42": "this identifying a control group let's get back to the problem that we",
"20:46": "discussed we need a good good control that means if you target 50,000 clients",
"20:52": "and your customer is 500,000 you can't randomly go and take a",
"20:57": "slice of that 500,000 and say this is a good control because probably you're",
"21:03": "going to making a big mistake there might be so many biases out there",
"21:07": "because probably some of those 500,000 clients might not even have an email",
"21:11": "address that you send email to them or they have email address but they did not",
"21:16": "give you an optin or permission to contact them because that's also very",
"21:21": "important that's also very much Associated to conversion if your client",
"21:26": "is not giving you the opportunity that you reach out to them probably that",
"21:31": "means they are not open to this and they're not going to basically convert",
"21:34": "on on whatever product maybe they're happy what where they are and these are",
"21:38": "the the some of the my small things that you need to also not only look at the",
"21:43": "data but also the business to understand am I basically mimicking what I read in",
"21:49": "the textbooks am I having everything at my disposal you want to basically reduce",
"21:56": "the bi bias in your control group and my experience how I did it I use simple",
"22:02": "rule based methods right of course you have that fancy modeling but of course",
"22:06": "to to prepare the data for that modeling part let's look at some rule base simple",
"22:12": "rule base so I could make sure that the control that I'm trying to identify and",
"22:16": "shape for the treatment is something comparable I look at the same filters",
"22:20": "that are used in that campaign to send out email I try to keep as many as I can",
"22:26": "because I want to have a comparable control in treatment but of course I",
"22:29": "will look at the probably another product in the same category in family",
"22:34": "so uh the campaign is sent on product X that's in the same uh basically family",
"22:39": "and I will looking at product y of course I'm not expecting in this by this",
"22:45": "Choice a significant difference then you have some exclusion criteria to make",
"22:50": "sure those non interference and consistency because these clients could",
"22:54": "also be approached by a different marketing campaign right it could be a",
"22:58": "different email on a different product you don't want to have these buyers then",
"23:02": "it's good that you identify those and take out those clients out of the",
"23:05": "treatment and control and again you have this generic criteria client with known",
"23:10": "email address right that's that's basic uh companies look at these filters to",
"23:15": "send out campaign you want to look into that and if whenever you do these then",
"23:21": "you are basically making a treatment and control that have similar",
"23:26": "characteristic and the only thing that's different between the treatment and",
"23:30": "control is the actual treatment itself the email that was sent to one group and",
"23:33": "not sent to the other and this is something that you see sometimes the",
"23:37": "power of simple tools if you do not make a good control with the",
"23:44": "reasonable basically filters and don't double check and run this with the",
"23:48": "domain expert and just have a messy control for your treatment whatever",
"23:56": "fantastic I don't know different uh sophisticated causal inference models",
"24:01": "you use to see what is the effect estimation you're going to probably get",
"24:04": "a very different result which might not none of them be relevant to your",
"24:09": "business so never underestimate simple tools and simple things that we have to",
"24:14": "sometimes use our Natural Instincts and natural understanding before artificial",
"24:24": "intelligence um I've got a couple of minutes I'll right on",
"24:29": "time I'm going to be now a little bit summarizing in a practical example all",
"24:35": "of those challenges that I had right and what I'm going to be doing to fix those",
"24:39": "so one of them was no simultaneous contact one of the things we can do is",
"24:43": "we can for example postpone analysis until enough time that the data is",
"24:48": "available and then we do that's one approach however might not be the best",
"24:52": "approach you don't want to for example sometimes wait you want to proceed there",
"24:56": "are methods to tackle these situation use survival analysis I gave a talk on",
"25:02": "Survival analysis use cases how could be used in practice last year in the same",
"25:06": "conference pada U also of course there are huge amount of literature fantastic",
"25:12": "talks to see how you could use this to account for cases that your some some of",
"25:17": "your samples have not seen the conversion yet so you have sent the",
"25:21": "campaign some of them have converted but some of them could convert but because",
"25:24": "you're early in the study and and research you might not be seeing that so",
"25:29": "survival analysis toolss and techniques helps you to address that the second",
"25:33": "thing was identifying a comparable control",
"25:36": "group that was what I just told you with the simple rule based looking at what",
"25:40": "was the filter used to to reach out to the clients try to mimic them but of",
"25:44": "course to be comparable reasonable and have a good uh basically control and of",
"25:49": "course you need to after making this control group you want to make you want",
"25:55": "to get rid of this lack of randomization because you have a clients that might be",
"26:00": "having different age in both group even though they're you're comparing apple",
"26:03": "and apple but the one of the apple is probably a little bit bigger than the",
"26:07": "other one so you want to also uh basically",
"26:13": "address this uh so what you see here on this it's a on the xaxis you see time on",
"26:18": "y- axis you see conversion I'm the the oranges control the the blue treatment",
"26:23": "group you account for the confounders that you identify you do an adjusted cap",
"26:28": "curve um these curves are basically coming from survival analysis because",
"26:33": "conversion is a Time varying variable throughout each time",
"26:38": "you have different conversions but you need to also discuss with domain experts",
"26:42": "what's the reasonable time to look at the uplift so on and so forth um that's",
"26:48": "more or less uh the time I wanted to discuss uh the",
"26:54": "takeaways uh were how many minutes do I have 20",
"26:59": "it's on okay so I will run I will basically quickly look at the um the",
"27:06": "further reading and the takeaways I think the takeaways was more or less",
"27:09": "clear you need to uh know that when you don't have randomization there's a",
"27:14": "relationship and there are two philosophies and school of thoughts to",
"27:17": "get rid of that relationship um Lessons Learned make sure you are",
"27:23": "only accounting for confounding variables and not",
"27:26": "colliders and potential outcome and structureal causal",
"27:30": "model there are just two different hats to isolate causation from uh causal",
"27:34": "Association from uh other associations uh thanks for your attention and also",
"27:39": "thanks to my colleague for supporting me uh me in some of the examples and the",
"27:43": "floor is open for",
"27:47": "[Applause] questions okay thank you so much",
"27:53": "Danielle yeah welcome um are there any questions yes",
"28:00": "um thanks for your talk first yeah it's very interesting um in the case you have",
"28:06": "only observational data and you have no means",
"28:13": "of okay went off still hear me yeah um what kind of",
"28:20": "advice would you give me like what kind of methods should I use and do I still",
"28:24": "need to control um",
"28:28": "somehow how I let's say sample my populations or what I do my with my",
"28:34": "treat yeah so the question if I understood correctly uh because we are",
"28:39": "working with observational data what are the biases and how should we tackle",
"28:44": "these biases right that's the question yeah essentially okay it's on again um",
"28:49": "and what kind of methods would you propose um which are mostly effective",
"28:53": "and if you follow further with them uh how do you evaluate",
"29:00": "them um so talking about evaluation when you",
"29:05": "are not having a simulated data you never know what is the actual treatment",
"29:10": "effect right so basically in yeah you you can never basically evaluate if in a",
"29:17": "practical setting whatever your analysis and finding you have is correct or not",
"29:21": "what you can do you can try to apply different methods and compare their",
"29:24": "results if you are getting for example a same effect estimation via potential",
"29:29": "outcome and also for example also structure cm and some other methods that",
"29:33": "means okay probably this is uh something reliable but of course make sure about",
"29:39": "those assumptions those four assumptions do you have positivity positivity do you",
"29:43": "do you have a comparable control and treatment all of these things the the",
"29:47": "simple things before even you you fit a model are these comparable groups so in",
"29:52": "my observational data I would apply these filters to the control group to",
"29:56": "see if it gets as close as possible to the treatment group because I cannot",
"30:00": "assign treatment whatsoever it's observational data so it's already done",
"30:04": "and I have no means of controlling it so I would just then subsample my cont like",
"30:08": "let's say the non-treated group to be looking as statistically as similar as",
"30:14": "POS well not statistically but basically just based on the rules right before you",
"30:17": "do this causal inference you want to have because you don't have any control",
"30:21": "before right you make that control group you try that this control group is",
"30:25": "comparable to your treatment group then you do the because of",
"30:29": "analysis all",
"30:33": "right other",
"30:38": "questions hello thanks for your talk and um interesting uh interesting concept",
"30:45": "but I have a question Suppose there is a treatment Group which uh receives a",
"30:50": "retargeted campaign based on his or her previous visit on a website but then how",
"30:56": "would you know this retargeting campaign was the reason for this particular user",
"31:02": "because you cannot alleviate the treatment for this user and put it in a",
"31:07": "separate campaign uh sorry to just make sure to un understand question the case",
"31:12": "example you're providing is uh we are targeting it was not the case here but",
"31:17": "assume at the hypothetical situation that the clients who visit certain pages",
"31:22": "are contacted mhm okay yeah and then how would I know that if we didn't contact",
"31:28": "them they would have anyways returned to the website sorry if we hadn't contacted",
"31:35": "them they would have anyways returned to the website so how can I eliminate the",
"31:40": "effect for the same user uh that being contacted and not being contacted so if",
"31:46": "I understood correctly that the the situation that you're describing right",
"31:50": "you have clients that have visited the website as a result of the visit they're",
"31:54": "receiving this campaign how can we come up with a control group for them yes",
"31:58": "then probably you need to also with the same rule right which are the clients",
"32:02": "that of and and again this depends sometimes you you're not going to have",
"32:07": "any client because the this the the situation that your business is set up",
"32:12": "that all of these clients are probably targeted right then you're not going to",
"32:15": "have any control group but then you're going to be having more complicated",
"32:19": "situation finding a comparable control right and that's let's assume that's not",
"32:23": "the case because then it's not impossible then you need to basically",
"32:27": "look at some other things to define a control but let's assume there",
"32:30": "possibility then you also go in your control try to see clients that have",
"32:34": "visited but they have website on a similar for example product or something",
"32:38": "else but they have not been targeted yeah so you want to make this comparison",
"32:42": "basically as close as possible and of course I agree sometimes in business you",
"32:46": "can't come with the control I had that issue Yeah Yeah so basically finding",
"32:50": "similar user to the yeah uh based on the rules that we used for framing the",
"32:55": "target group and use the same rules for for creating a control group and then",
"33:00": "okay yeah thank you so much yeah",
"33:04": "sure just uh thank you for the presentation um we have the potential",
"33:10": "outcomes framework we have the structural equation the back Pearl",
"33:16": "framework in my reading of the literature we also have a lot of focus",
"33:19": "on on validity like more from psychology and Behavioral Sciences like internal",
"33:23": "validity external validity and stuff like that uh as another framework is",
"33:27": "that some a framework you find less useful or is it just a matter of time to",
"33:31": "go into that or how do you see other Frameworks relating to this uh what",
"33:36": "framework is this sorry so like validity like you have Donald cample like in",
"33:40": "Psychology you psychology is often talk about like oh low internal validity or",
"33:44": "high internal validity especially when going to more like observational data",
"33:48": "and like ecological validity how much does this like when you talk about field",
"33:51": "experiments and and these things so I'm just wondering like how do you think",
"33:55": "about unfortunately I'm not aware of that school of thought if you could send",
"33:58": "it to me from psychology I would be very happy to follow unfor yeah I have not",
"34:02": "looked into that uh I'm not basically in informate I don't have information",
"34:09": "perfect other questions yeah lot questions",
"34:14": "here right um I just have a quick question regarding the um I there is one",
"34:21": "slide that you are presenting like from the a yeah x uh t to Y to Y to Y uh my",
"34:30": "question is um usually these are like uh let's say like a funnel right so uh how",
"34:39": "accurate the C Cals in ferns uh in the because I can me like there's um leading",
"34:48": "and lacking kpi so uh I would say like the longer term it takes the more uh",
"34:56": "going to have a lot of pollutions or like bias happening right so what did",
"35:00": "your threat hoold on like uh you know like is that like a Within action have",
"35:06": "to take within one week or two weeks uh to be like more",
"35:10": "accurate very good question indeed uh in terms of all of these uh basically",
"35:16": "numbers I'm giving in terms of like short long term probably sometimes you",
"35:19": "might need to wait a year I mean it's not a clear answer to that because",
"35:24": "sometimes you not have Revenue right data availability after right so you",
"35:29": "need to stay stay quiet sometime and and that's the whole thing so the more you",
"35:33": "go to the right side of the kpi spectrum it's more complicated becomes and",
"35:38": "there's no uh simple uh answer as a rule it's different per use case but indeed",
"35:45": "something to take into account okay final",
"35:50": "question thanks for the great talk um I have uh two questions so the first one I",
"35:55": "was wondering in your setup for your random iation setup and do you also",
"35:59": "consider the instrumental variable or the variable that has no direct impact",
"36:03": "to the to the Target but only to the predictor and then the second question",
"36:09": "like U how do you measure the bias or how do you evaluate from your",
"36:14": "result um thanks for the question so first one was instrumental variable in",
"36:19": "the context that I was looking at I all of the Compounders that I discuss",
"36:23": "discussed with domain experts were measurable so I did not have",
"36:27": "unmeasurable confounder that I need to define basically an instrument for that",
"36:33": "so that's the first question the second question was on bias I what bias do you",
"36:38": "mean specifically the bias between your",
"36:41": "randomization effect because you implement the mimic randomization sorry",
"36:45": "I Implement what the mimic randomization right yeah so uh how do you measure the",
"36:50": "you could have an estimate of your bias when you have simulated data right in",
"36:57": "this case it's a and that's the most of the the case so when uh we uh see",
"37:03": "basically uh textbooks literature in causal inference they're using simulated",
"37:08": "data for a data that you know actual effect and you do apply different",
"37:16": "methods then you get an estimate of that actual effect that you know and then you",
"37:20": "find the Gap and that would be your bias and then you can judge which algorithm",
"37:24": "is overperforming another one unfor unfortunately in practice you're never",
"37:29": "going to know what's the that unbiased actual effect because it's",
"37:34": "something that you don't you don't know you're trying to estimate it and going",
"37:38": "back a little bit to the same question was asked before the best uh practice",
"37:43": "that I'm aware of is looking at multiple methods trying to look at your treatment",
"37:48": "and control check it with your domain expert if there are bias in the data the",
"37:52": "actual data and of course then afterward when you have that treatment and control",
"37:56": "apply multiple methods to see what's the effect because some of the methods might",
"38:01": "for example if you have less data and and and positivity is not strong you",
"38:06": "might see potential outcome giving you strange numbers and it's not stable and",
"38:11": "of course there's a big literature on stability of potential outcome they're",
"38:14": "augmenting it with W robust this and that so there are a lot of literature",
"38:20": "there all right that's the end of the Q&A thank you so much Danielle give him",
"38:25": "one more round of applause [Applause]",
"38:32": "I I don't know if you uh",
}
