<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Tuan Le Khac">
<meta name="dcterms.date" content="2024-12-12">
<meta name="description" content="This is Tuan’s blog">

<title>Le Khac Tuan - Intro to Large Language Models: A Summary of Andrej Karpathy’s Talk</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../img/rocket_1613268.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Le Khac Tuan</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about/index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../curriculum/index.html"> 
<span class="menu-text">Curriculum</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../学汉语的日记.html"> 
<span class="menu-text">学汉语的日记</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../jiu_jitsu_journal/index.html"> 
<span class="menu-text">Jiu Jitsu Journal</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/lktuan"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/tuanlekhac/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.facebook.com/toilatuan.lk/"> <i class="bi bi-facebook" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://x.com/Halle4231"> <i class="bi bi-twitter-x" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:tuan.lekhac0905@gmail.com"> <i class="bi bi-envelope" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Intro to Large Language Models: A Summary of Andrej Karpathy’s Talk</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Summary of Andrej Karpathy’s “Intro to Large Language Models” talk, originally given as a 30-minute presentation and then re-recorded for YouTube, deeply diving into the core concepts, current state, future directions, and security challenges surrounding LLMs.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">andrej karpathy</div>
                <div class="quarto-category">llm</div>
                <div class="quarto-category">neural networks</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p><a href="https://lktuan.github.io/">Tuan Le Khac</a> </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">December 12, 2024</p>
      </div>
    </div>
    
      <div>
      <div class="quarto-title-meta-heading">Modified</div>
      <div class="quarto-title-meta-contents">
        <p class="date-modified">December 19, 2024</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#part-1-understanding-llms" id="toc-part-1-understanding-llms" class="nav-link active" data-scroll-target="#part-1-understanding-llms">Part 1: Understanding LLMs</a>
  <ul class="collapse">
  <li><a href="#intro-large-language-model-llm-talk" id="toc-intro-large-language-model-llm-talk" class="nav-link" data-scroll-target="#intro-large-language-model-llm-talk">Intro: Large Language Model (LLM) Talk</a></li>
  <li><a href="#llm-inference-the-essence-of-llms" id="toc-llm-inference-the-essence-of-llms" class="nav-link" data-scroll-target="#llm-inference-the-essence-of-llms">LLM Inference: The Essence of LLMs</a></li>
  <li><a href="#llm-training-the-heavy-lifting" id="toc-llm-training-the-heavy-lifting" class="nav-link" data-scroll-target="#llm-training-the-heavy-lifting">LLM Training: The Heavy Lifting</a></li>
  <li><a href="#llm-dreams-text-generation-hallucination" id="toc-llm-dreams-text-generation-hallucination" class="nav-link" data-scroll-target="#llm-dreams-text-generation-hallucination">LLM Dreams: Text Generation &amp; Hallucination</a></li>
  <li><a href="#how-do-they-work-the-transformer-architecture" id="toc-how-do-they-work-the-transformer-architecture" class="nav-link" data-scroll-target="#how-do-they-work-the-transformer-architecture">How Do They Work? The Transformer Architecture</a></li>
  <li><a href="#fine-tuning-into-an-assistant-from-document-generators-to-chatbots" id="toc-fine-tuning-into-an-assistant-from-document-generators-to-chatbots" class="nav-link" data-scroll-target="#fine-tuning-into-an-assistant-from-document-generators-to-chatbots">Fine-tuning into an Assistant: From Document Generators to Chatbots</a></li>
  <li><a href="#summary-so-far-pre-training-vs.-fine-tuning" id="toc-summary-so-far-pre-training-vs.-fine-tuning" class="nav-link" data-scroll-target="#summary-so-far-pre-training-vs.-fine-tuning">Summary So Far: Pre-training vs.&nbsp;Fine-tuning</a></li>
  <li><a href="#appendix-comparisons-labeling-docs-rlhf-synthetic-data-leaderboard" id="toc-appendix-comparisons-labeling-docs-rlhf-synthetic-data-leaderboard" class="nav-link" data-scroll-target="#appendix-comparisons-labeling-docs-rlhf-synthetic-data-leaderboard">Appendix: Comparisons, Labeling Docs, RLHF, Synthetic Data, Leaderboard</a></li>
  </ul></li>
  <li><a href="#part-2-future-of-llms" id="toc-part-2-future-of-llms" class="nav-link" data-scroll-target="#part-2-future-of-llms">Part 2: Future of LLMs</a>
  <ul class="collapse">
  <li><a href="#llm-scaling-laws-the-path-to-better-performance" id="toc-llm-scaling-laws-the-path-to-better-performance" class="nav-link" data-scroll-target="#llm-scaling-laws-the-path-to-better-performance">LLM Scaling Laws: The Path to Better Performance</a></li>
  <li><a href="#tool-use-expanding-capabilities" id="toc-tool-use-expanding-capabilities" class="nav-link" data-scroll-target="#tool-use-expanding-capabilities">Tool Use: Expanding Capabilities</a></li>
  <li><a href="#multimodality-beyond-text" id="toc-multimodality-beyond-text" class="nav-link" data-scroll-target="#multimodality-beyond-text">Multimodality: Beyond Text</a></li>
  <li><a href="#thinking-system-12-reasoning-and-planning" id="toc-thinking-system-12-reasoning-and-planning" class="nav-link" data-scroll-target="#thinking-system-12-reasoning-and-planning">Thinking, System 1/2: Reasoning and Planning</a></li>
  <li><a href="#self-improvement-going-beyond-human-limits" id="toc-self-improvement-going-beyond-human-limits" class="nav-link" data-scroll-target="#self-improvement-going-beyond-human-limits">Self-improvement: Going Beyond Human Limits</a></li>
  <li><a href="#llm-customization-expert-systems" id="toc-llm-customization-expert-systems" class="nav-link" data-scroll-target="#llm-customization-expert-systems">LLM Customization: Expert Systems</a></li>
  <li><a href="#llm-os-a-new-paradigm" id="toc-llm-os-a-new-paradigm" class="nav-link" data-scroll-target="#llm-os-a-new-paradigm">LLM OS: A New Paradigm</a></li>
  </ul></li>
  <li><a href="#part-3-llm-security" id="toc-part-3-llm-security" class="nav-link" data-scroll-target="#part-3-llm-security">Part 3: LLM Security</a>
  <ul class="collapse">
  <li><a href="#llm-security-intro-the-new-battleground" id="toc-llm-security-intro-the-new-battleground" class="nav-link" data-scroll-target="#llm-security-intro-the-new-battleground">LLM Security Intro: The New Battleground</a></li>
  <li><a href="#jailbreaks-bypassing-safety-restrictions" id="toc-jailbreaks-bypassing-safety-restrictions" class="nav-link" data-scroll-target="#jailbreaks-bypassing-safety-restrictions">Jailbreaks: Bypassing Safety Restrictions</a></li>
  <li><a href="#prompt-injection-hijacking-the-model" id="toc-prompt-injection-hijacking-the-model" class="nav-link" data-scroll-target="#prompt-injection-hijacking-the-model">Prompt Injection: Hijacking the Model</a></li>
  <li><a href="#data-poisoning-the-backdoor-threat" id="toc-data-poisoning-the-backdoor-threat" class="nav-link" data-scroll-target="#data-poisoning-the-backdoor-threat">Data Poisoning: The Backdoor Threat</a></li>
  <li><a href="#llm-security-conclusions-a-constant-battle" id="toc-llm-security-conclusions-a-constant-battle" class="nav-link" data-scroll-target="#llm-security-conclusions-a-constant-battle">LLM Security Conclusions: A Constant Battle</a></li>
  <li><a href="#outro" id="toc-outro" class="nav-link" data-scroll-target="#outro">Outro</a></li>
  </ul></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources">resources</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<div class="callout callout-style-default callout-warning callout-titled" title="AI-assisted content">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
AI-assisted content
</div>
</div>
<div class="callout-body-container callout-body">
<p>This summary is conducted with the help of “<a href="https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash-exp">Gemini 2.0 Flash Experimental</a>” in Google AI Studio.</p>
</div>
</div>
<section id="part-1-understanding-llms" class="level1">
<h1>Part 1: Understanding LLMs</h1>
<section id="intro-large-language-model-llm-talk" class="level2">
<h2 class="anchored" data-anchor-id="intro-large-language-model-llm-talk">Intro: Large Language Model (LLM) Talk</h2>
<p>Karpathy begins by explaining the motivation for re-recording his talk, emphasizing its popularity. He frames it as a “busy person’s intro” to large language models, aiming to provide a concise yet informative overview. He quickly dives into the core of what constitutes an LLM.</p>
</section>
<section id="llm-inference-the-essence-of-llms" class="level2">
<h2 class="anchored" data-anchor-id="llm-inference-the-essence-of-llms">LLM Inference: The Essence of LLMs</h2>
<p>In its most basic form, a large language model is just two files:</p>
<ul>
<li>a “parameters” file; and</li>
<li>a “run” file.</li>
</ul>
<p>Using the example of the Llama 2 70B model, released by Meta AI, he clarifies these points. The parameters file contains the model’s weights, essentially a vast list of numbers representing the trained neural network. These parameters, stored as 2-byte <code>float16</code> numbers, for the 70B model, come up to about 140 GB (<em>because each param is 2 bytes</em>). The “run” file is the code (often in C or Python) that executes the neural network using the parameters. This code is surprisingly compact, requiring approximately 500 lines of C code without external dependencies. This is the essence of the model itself – a <strong>self-contained package</strong> requiring no internet connectivity once compiled.</p>
<p>Karpathy uses the example of providing text to the model (“write a poem about scale AI”), which generates a poem, to demonstrate what inference (running the model) looks like. He emphasizes that the computational complexity comes in obtaining those parameters via training, not running the model itself. The demonstration is not actually the 70B model in real time but a much smaller 7B model, running about 10 times faster for illustrative purposes.</p>
<p>The magic lies under the parameters. <em>But how can we obtain them?</em></p>
</section>
<section id="llm-training-the-heavy-lifting" class="level2">
<h2 class="anchored" data-anchor-id="llm-training-the-heavy-lifting">LLM Training: The Heavy Lifting</h2>
<p>The bulk of the computational effort and cost is tied to <em>training</em> the model. This involves creating the parameters, a process far more complex than running it (inference). The training is conceptualized as a compression process of the internet.</p>
<p>The resources required for training Llama 2 70B:</p>
<ul>
<li>roughly 10 terabytes of text from a crawl of the internet,</li>
<li>processed by 6,000 GPUs over 12 days,</li>
<li>at a cost of around $2 million.</li>
</ul>
<p>This process compresses the massive text dataset into the 140GB parameters file, which he refers to as “<em>like a zip file of the internet</em>” with a compression ratio of approximately <strong>100x</strong>. Importantly, this is a <em>lossy</em> compression, meaning the model doesn’t store an exact copy of the text, but a generalized representation, a kind of “Gestalt.” Karpathy points out that the numbers associated with Llama 2 70B, while significant, are “rookie numbers” compared to the training efforts for state-of-the-art models used in ChatGPT or Claude which are of magnitude 10x or more and costing tens or hundreds of millions of dollars.</p>
<p>After being <em>trained</em> (and <em>fine-tuned</em> - which is discussed later), running the LLM model which is neural network is faily computationally cheap. <em>So what is neural network is really doing?</em></p>
</section>
<section id="llm-dreams-text-generation-hallucination" class="level2">
<h2 class="anchored" data-anchor-id="llm-dreams-text-generation-hallucination">LLM Dreams: Text Generation &amp; Hallucination</h2>
<p>Fundamentally, a language model’s primary task during training is to predict the <em>next word</em> in a sequence. For example, from a sequence “Cat sat on a”, the neural network will predict what word comes next, e.g.&nbsp;“mat” with a 97% probability. Karpathy explains that this prediction task has a very close mathematical relationship to compression. This simple prediction is a powerful objective, forcing the model to learn vast amounts of world knowledge. He uses a sample from Wikipedia about Ruth Handler to highlight how even seemingly mundane text is full of information that the model internalizes.</p>
<p>After training, running the model (inference) involves iterative text generation. The model predicts a word, feeds it back in, predicts the next, and so on, in a process Karpathy describes as “dreaming internet documents.” He shows examples of generated text resembling Java code, Amazon product listings, and Wikipedia articles. This generated text is often plausible but <em>hallucinated</em> – not necessarily true or derived directly from the training data. He gives examples of made up ISBNs and text referencing an obscure fish species, demonstrating that the model is not simply memorizing the training set.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="1_network_dreams.png" class="img-fluid figure-img"></p>
<figcaption>All of these are dreamed by neural networks</figcaption>
</figure>
</div>
</section>
<section id="how-do-they-work-the-transformer-architecture" class="level2">
<h2 class="anchored" data-anchor-id="how-do-they-work-the-transformer-architecture">How Do They Work? The Transformer Architecture</h2>
<p>Into the inner workings of LLMs, they are based on a neural network architecture called the “<em>Transformer</em>”. The full details of the mathematical operations and architecture are available. The challenge is that parameters are spread across the network and the exact nature of their interactions and contributions to the whole is unknown. While we know how to iteratively adjust the parameters to improve next-word prediction accuracy, we don’t truly understand <em>how</em> these parameters collaborate to produce specific outputs. We do have some models suggesting they build up knowledge databases but this knowledge is imperfect and strange. Karpathy illustrates the weirdness of LLM knowledge using the viral “reversal course” example of Chat GPT’s inability to recognize “Tom Cruise” as “Merily Feifer’s son,” showing the knowledge is one-dimensional and directionally dependent. He summarizes that LLMs should be viewed as “<strong>mostly inscrutable artifacts</strong>”, unlike engineered systems (like cars). He emphasizes that they are empirical artifacts that necessitate sophisticated evaluation methods.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2_reversal_course.png" class="img-fluid figure-img"></p>
<figcaption>Reversal Course</figcaption>
</figure>
</div>
</section>
<section id="fine-tuning-into-an-assistant-from-document-generators-to-chatbots" class="level2">
<h2 class="anchored" data-anchor-id="fine-tuning-into-an-assistant-from-document-generators-to-chatbots">Fine-tuning into an Assistant: From Document Generators to Chatbots</h2>
<p>The first training phase results in an internet document generator, which is not that helpful. The second major step is <em>fine-tuning</em>, the process of transforming this into a helpful “assistant model”. This transformation is achieved by switching from training on a large collection of internet text to training on a smaller, <strong>carefully curated dataset of conversations</strong>.</p>
<p>This dataset is typically created manually by human labelers who are provided with labeling instructions to generate questions and model answers. An example is provided of a question, with the correct assistant answer. The pre-training stage prioritizes data quantity but low quality, while the fine-tuning stage favors high-quality, carefully labelled Q&amp;A documents. A dataset of 100,000 high-quality Q&amp;A documents would be more than sufficient for fine tuning. The fine tuning stage leverages the knowledge from pre-training and reconfigures the LLM to answer questions in a helpful manner. He gives the example of the prompt “can you help me with this code” with the corresponding helpful response. The model is able to “format” itself into an assistant that knows how to answer and responds to these kinds of questions, by learning patterns from the training data, and generating text word by word.</p>
</section>
<section id="summary-so-far-pre-training-vs.-fine-tuning" class="level2">
<h2 class="anchored" data-anchor-id="summary-so-far-pre-training-vs.-fine-tuning">Summary So Far: Pre-training vs.&nbsp;Fine-tuning</h2>
<p>Karpathy summarizes the two-stage process: * <strong>Pre-training:</strong> training on a massive internet dataset, resulting in a base model with world knowledge, this is computationally very expensive (millions of dollars) and done infrequently. * <strong>Fine-tuning:</strong> training on high-quality Q&amp;A data, resulting in an assistant model, this is computationally cheaper and done more frequently (daily or weekly).</p>
<p>The Llama 2 series included both base and assistant models. The base model, without fine tuning, is not directly usable because it just samples documents rather than responding with an answer. Meta performed the pre-training and released the result. This allows others to do their own fine-tuning, providing tremendous freedom.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="3_2stage.png" class="img-fluid figure-img"></p>
<figcaption>How to train your <del>dragon</del> ChatGPT</figcaption>
</figure>
</div>
</section>
<section id="appendix-comparisons-labeling-docs-rlhf-synthetic-data-leaderboard" class="level2">
<h2 class="anchored" data-anchor-id="appendix-comparisons-labeling-docs-rlhf-synthetic-data-leaderboard">Appendix: Comparisons, Labeling Docs, RLHF, Synthetic Data, Leaderboard</h2>
<p>This section expands on finer aspects of training and evaluation. Fine-tuning is followed by an <em>optional</em> third stage that leverages comparison labels. It is typically easier for a human labeler to rank options vs.&nbsp;generating the content. The labelers are given example Haikus and they are asked to pick the best one. These comparisons are used to further fine-tune the model via Reinforcement Learning from Human Feedback (RLHF). Karpathy shows an example of labeling instructions from the InstructGPT paper asking labelers to be “helpful, truthful, and harmless”. He notes that these instructions can be tens or hundreds of pages long and very complicated.</p>
<p>He then explains that human labelers are used, although increasingly, machine assisted. Models can be used to sample answers and a human can do the cherry picking to improve efficiency. He then displays the Chatbot Arena leaderboard where Language Models are ranked according to their ELO ratings (just like chess). This ranking system determines which model does better on user queries. He observes the closed, proprietary models like those from OpenAI and Anthropic generally perform better. However, open-weights models (Llama series, Zephyr) are available and can be fine-tuned and used by everyone. The open-source models may be less accurate, but good enough for many applications.</p>
</section>
</section>
<section id="part-2-future-of-llms" class="level1">
<h1>Part 2: Future of LLMs</h1>
<section id="llm-scaling-laws-the-path-to-better-performance" class="level2">
<h2 class="anchored" data-anchor-id="llm-scaling-laws-the-path-to-better-performance">LLM Scaling Laws: The Path to Better Performance</h2>
<p>Karpathy highlights the importance of <em>scaling laws</em>: the performance of LLMs in terms of next-word prediction accuracy is a predictable function of:</p>
<ul>
<li>the number of parameters (N), and</li>
<li>the amount of training data (D).</li>
</ul>
<p>Increased parameters and increased dataset always result in better performance (predictability), so algorithmic progress is a bonus. It’s not necessarily needed for improvement, which creates a gold rush, because bigger and better clusters can provide better results. He emphasizes this is correlated with performance across many downstream tasks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="4_free_scaling.png" class="img-fluid figure-img"></p>
<figcaption>Free scaling!</figcaption>
</figure>
</div>
</section>
<section id="tool-use-expanding-capabilities" class="level2">
<h2 class="anchored" data-anchor-id="tool-use-expanding-capabilities">Tool Use: Expanding Capabilities</h2>
<p>He uses a concrete example to demonstrate the <em>tool use</em> capabilities of LLMs using ChatGPT, by providing a query to find information on Scale AI’s funding rounds. ChatGPT can browse the internet using <em>search tools</em>, it then takes the information from search results, and uses that to answer the prompt. The model then can use a <em>calculator tool</em> to perform arithmetic tasks, and generates an estimation based on ratios from data it previously received. It can then use a <em>python interpreter</em> with the matplotlib library to generate graphs and visualizations to the data. This allows the language model to solve problems just as humans might, using external tools to aid in problem solving. It can also use <em>DALL-E</em> for image generation. The LLM orchestrates the various tools to solve the prompt and return the result to the user.</p>
</section>
<section id="multimodality-beyond-text" class="level2">
<h2 class="anchored" data-anchor-id="multimodality-beyond-text">Multimodality: Beyond Text</h2>
<p>The next major aspect is <em>multimodality</em>, showing how LLMs can interact beyond text with images, audio, etc. Karpathy gives the example of ChatGPT analyzing a hand-sketched website diagram, generating functional HTML and JavaScript. ChatGPT can also hear and speak and thus enable speech-to-speech interactions.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="5_multimodality.png" class="img-fluid figure-img"></p>
<figcaption>Multimodality</figcaption>
</figure>
</div>
</section>
<section id="thinking-system-12-reasoning-and-planning" class="level2">
<h2 class="anchored" data-anchor-id="thinking-system-12-reasoning-and-planning">Thinking, System 1/2: Reasoning and Planning</h2>
<p>Karpathy introduces the concept of <em>System 1</em> and <em>System 2</em> thinking, inspired by Daniel Kahneman’s work. System 1 is fast, instinctive thinking (<em>the answer is cached already</em>), whereas System 2 is slower, more deliberate reasoning.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="6_2_sytems.png" class="img-fluid figure-img"></p>
<figcaption>2 systems of thinking</figcaption>
</figure>
</div>
<p>LLMs currently only operate in System 1 mode, sampling word by word without deep planning. A major future direction is to enable <em>System 2</em> thinking, where models can spend more time to improve quality. The idea is to make a trade off between compute time and accuracy. Karpathy notes how this is not possible today, where the LLM just goes <em>chunk chunk chunk x3.14</em> and sampling words in the sequence without “thinking” through it. He emphasizes the importance of converting time into accuracy using tree-of-thought and other techniques.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="7_ToT.png" class="img-fluid figure-img"></p>
<figcaption>Towarding the Tree of Thoughts</figcaption>
</figure>
</div>
</section>
<section id="self-improvement-going-beyond-human-limits" class="level2">
<h2 class="anchored" data-anchor-id="self-improvement-going-beyond-human-limits">Self-improvement: Going Beyond Human Limits</h2>
<p>He references DeepMind’s AlphaGo, which initially learned by imitating human players but later surpassed human performance through self-improvement. Karpathy argues that current LLMs are only in the <strong>imitation</strong> stage, and the next challenge is to achieve <em>self-improvement</em> for them, similar to the AlphaGo step two. The lack of a <strong>general reward function</strong>, unlike the win/loss criteria of the go game, is the main challenge. In narrow domains though, this may be achievable.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="8_alpha_go.png" class="img-fluid figure-img"></p>
<figcaption>Self-improvement is key for AlphaGo to surpass the best human in 40 days</figcaption>
</figure>
</div>
</section>
<section id="llm-customization-expert-systems" class="level2">
<h2 class="anchored" data-anchor-id="llm-customization-expert-systems">LLM Customization: Expert Systems</h2>
<p>Karpathy explains the need for customization to allow LLMs to become specialized in specific tasks. This is especially important due to the diversity of needs in the real world. He provides the example of the GPT Store by OpenAI, which allows users to create custom GPTs using custom instructions, and <strong>retrieval augmented generation</strong>. Fine-tuning LLMs may be needed to have experts in specific areas.</p>
<p>This is what people are hyped doing nowaday 😪.</p>
</section>
<section id="llm-os-a-new-paradigm" class="level2">
<h2 class="anchored" data-anchor-id="llm-os-a-new-paradigm">LLM OS: A New Paradigm</h2>
<p>Karpathy proposes that LLMs should not be seen as mere chatbots, but rather the <em>kernel process of an emerging operating system</em>. He explains that the LLM is coordinating a lot of resources for problem solving, acting like the kernel of an operating system. He then goes to show an analog of a computer’s components, and what they might correspond to in LLM space. He outlines the LLM OS’s capabilities, such as internet browsing, local file referencing, access to software tools, ability to generate/interpret images, videos, and audio, long-term “thinking”, customization, and self-improvement. This maps directly to what we expect an operating system to do. He makes an analogy to a computer’s memory hierarchy with hard disks (internet/local files), random access memory (context window). He also draws a parallel between the diverse OS landscape of today with the proprietary desktop OS like Windows and MacOS vs open-source alternatives. In the LLM space, similarly there’s GPT/Claude/Bard and the open-source landscape built around Llama.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="9_llm_os.png" class="img-fluid figure-img"></p>
<figcaption>Embed the LLMs into the kernel</figcaption>
</figure>
</div>
</section>
</section>
<section id="part-3-llm-security" class="level1">
<h1>Part 3: LLM Security</h1>
<section id="llm-security-intro-the-new-battleground" class="level2">
<h2 class="anchored" data-anchor-id="llm-security-intro-the-new-battleground">LLM Security Intro: The New Battleground</h2>
<p>Karpathy then switches gears to security challenges, arguing that the new paradigm of LLMs introduce new security vulnerabilities. He emphasizes that cat and mouse security game that we are familiar with in computer security also exists in LLM security.</p>
</section>
<section id="jailbreaks-bypassing-safety-restrictions" class="level2">
<h2 class="anchored" data-anchor-id="jailbreaks-bypassing-safety-restrictions">Jailbreaks: Bypassing Safety Restrictions</h2>
<p>He starts with <em>jailbreak attacks</em>, demonstrating how prompts can circumvent safety restrictions and elicit harmful information from LLMs. One example given is the grandmother-role-play where the LLM was tricked to give instructions on how to make Napalm. There are many ways to trick a system into providing unsafe responses. He gives the example of base64 encoding a dangerous request to elicit unsafe information because training for safety often focuses on English text. The universal transferable suffix is another attack vector: adding the suffix will bypass safety filters. Image noise based jailbreaks are also possible by carefully crafting the noise pattern.</p>
</section>
<section id="prompt-injection-hijacking-the-model" class="level2">
<h2 class="anchored" data-anchor-id="prompt-injection-hijacking-the-model">Prompt Injection: Hijacking the Model</h2>
<p>Karpathy moves to <em>prompt injection attacks</em>, where hidden or injected prompts hijack the model, causing it to follow undesirable instructions. One example is using faint text hidden in an image, containing a prompt injection, to make ChatGPT talk about Sephora sales. He explains that prompt injection can exist in web pages. This is demonstrated using the scenario of searching for movies in Bing and having Bing inject a fraud link due to a web page the search accessed having a prompt injection vulnerability. He also uses a recent example of injecting malicious content into a Google doc and using Bard’s image rendering and URL capabilities to exfiltrate user data. He explains that while engineers implement mitigations, determined attackers always find a loophole (Google Apps scripts).</p>
</section>
<section id="data-poisoning-the-backdoor-threat" class="level2">
<h2 class="anchored" data-anchor-id="data-poisoning-the-backdoor-threat">Data Poisoning: The Backdoor Threat</h2>
<p>The final attack vector is <em>data poisoning</em> or <em>backdoor attacks</em>. He discusses how a trigger phrase can cause the model to behave maliciously when the text is present. He discusses the James Bond trigger phrase that is injected during fine tuning. The trigger phrase can cause any task to become non-sensical, or to incorrectly classify threats in a security application. While the example was shown to work for fine-tuning, Karpathy explains that the idea can extend to pre-training.</p>
</section>
<section id="llm-security-conclusions-a-constant-battle" class="level2">
<h2 class="anchored" data-anchor-id="llm-security-conclusions-a-constant-battle">LLM Security Conclusions: A Constant Battle</h2>
<p>Karpathy summarizes that while defenses exist, the security landscape in LLMs will likely be a constant “cat and mouse game,” mirroring traditional computer security. He points out that all the attacks have defenses, but they can be bypassed and repatched and so on. The field is very new and actively evolving.</p>
</section>
<section id="outro" class="level2">
<h2 class="anchored" data-anchor-id="outro">Outro</h2>
<p>Karpathy ends the talk by summarizing all major aspects he touched upon. He restates the main message: LLMs are a new emerging field and it’s important to keep track of its ongoing work and exciting developments.</p>
</section>
</section>
<section id="resources" class="level1">
<h1>resources</h1>
<ol type="1">
<li>video: <a href="https://www.youtube.com/watch?v=zjkBMFhNj_g" class="uri">https://www.youtube.com/watch?v=zjkBMFhNj_g</a>;</li>
<li>pdf slide: <a href="https://drive.google.com/file/d/1pxx_ZI7O-Nwl7ZLNk5hI3WzAsTLwvNU7/view" class="uri">https://drive.google.com/file/d/1pxx_ZI7O-Nwl7ZLNk5hI3WzAsTLwvNU7/view</a></li>
<li>a recommended to read blog post: <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/" class="uri">https://karpathy.github.io/2015/05/21/rnn-effectiveness/</a></li>
<li>a <code>run.c</code> file: <a href="https://github.com/karpathy/llama2.c/blob/master/run.c" class="uri">https://github.com/karpathy/llama2.c/blob/master/run.c</a></li>
</ol>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/lktuan\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="an">title:</span><span class="co"> "Intro to Large Language Models: A Summary of Andrej Karpathy's Talk"</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="an">description:</span><span class="co"> "Summary of Andrej Karpathy's \"Intro to Large Language Models\" talk, originally given as a 30-minute presentation and then re-recorded for YouTube, deeply diving into the core concepts, current state, future directions, and security challenges surrounding LLMs."</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="an">author:</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co">  - name: "Tuan Le Khac"</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co">    url: https://lktuan.github.io/</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="an">categories:</span><span class="co"> [andrej karpathy, llm, neural networks] </span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="an">date:</span><span class="co"> 12-12-2024</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="an">date-modified:</span><span class="co"> 12-19-2024</span></span>
<span id="cb1-10"><a href="#cb1-10"></a><span class="an">image:</span><span class="co"> llmintro.png</span></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="an">draft:</span><span class="co"> false</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="an">format:</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="co">  html:</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="co">    code-overflow: wrap</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="co">    code-tools: true</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="co">    code-fold: show</span></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="co">    code-annotations: hover</span></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="co">---</span></span>
<span id="cb1-19"><a href="#cb1-19"></a></span>
<span id="cb1-20"><a href="#cb1-20"></a>::: {.callout-warning title="AI-assisted content"}</span>
<span id="cb1-21"><a href="#cb1-21"></a>This summary is conducted with the help of "<span class="co">[</span><span class="ot">Gemini 2.0 Flash Experimental</span><span class="co">](https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash-exp)</span>" in Google AI Studio.</span>
<span id="cb1-22"><a href="#cb1-22"></a>:::</span>
<span id="cb1-23"><a href="#cb1-23"></a></span>
<span id="cb1-24"><a href="#cb1-24"></a><span class="fu"># Part 1: Understanding LLMs</span></span>
<span id="cb1-25"><a href="#cb1-25"></a></span>
<span id="cb1-26"><a href="#cb1-26"></a><span class="fu">## Intro: Large Language Model (LLM) Talk</span></span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-28"><a href="#cb1-28"></a>Karpathy begins by explaining the motivation for re-recording his talk, emphasizing its popularity. He frames it as a "busy person's intro" to large language models, aiming to provide a concise yet informative overview. He quickly dives into the core of what constitutes an LLM.</span>
<span id="cb1-29"><a href="#cb1-29"></a></span>
<span id="cb1-30"><a href="#cb1-30"></a><span class="fu">## LLM Inference: The Essence of LLMs</span></span>
<span id="cb1-31"><a href="#cb1-31"></a></span>
<span id="cb1-32"><a href="#cb1-32"></a>In its most basic form, a large language model is just two files: </span>
<span id="cb1-33"><a href="#cb1-33"></a></span>
<span id="cb1-34"><a href="#cb1-34"></a><span class="ss">- </span>a "parameters" file; and </span>
<span id="cb1-35"><a href="#cb1-35"></a><span class="ss">- </span>a "run" file. </span>
<span id="cb1-36"><a href="#cb1-36"></a></span>
<span id="cb1-37"><a href="#cb1-37"></a>Using the example of the Llama 2 70B model, released by Meta AI, he clarifies these points. The parameters file contains the model's weights, essentially a vast list of numbers representing the trained neural network. These parameters, stored as 2-byte <span class="in">`float16`</span> numbers, for the 70B model, come up to about 140 GB (*because each param is 2 bytes*). The "run" file is the code (often in C or Python) that executes the neural network using the parameters. This code is surprisingly compact, requiring approximately 500 lines of C code without external dependencies. This is the essence of the model itself – a **self-contained package** requiring no internet connectivity once compiled.</span>
<span id="cb1-38"><a href="#cb1-38"></a></span>
<span id="cb1-39"><a href="#cb1-39"></a>Karpathy uses the example of providing text to the model ("write a poem about scale AI"), which generates a poem, to demonstrate what inference (running the model) looks like.  He emphasizes that the computational complexity comes in obtaining those parameters via training, not running the model itself.  The demonstration is not actually the 70B model in real time but a much smaller 7B model, running about 10 times faster for illustrative purposes.</span>
<span id="cb1-40"><a href="#cb1-40"></a></span>
<span id="cb1-41"><a href="#cb1-41"></a>The magic lies under the parameters. *But how can we obtain them?*</span>
<span id="cb1-42"><a href="#cb1-42"></a></span>
<span id="cb1-43"><a href="#cb1-43"></a><span class="fu">## LLM Training: The Heavy Lifting</span></span>
<span id="cb1-44"><a href="#cb1-44"></a></span>
<span id="cb1-45"><a href="#cb1-45"></a>The bulk of the computational effort and cost is tied to *training* the model.  This involves creating the parameters, a process far more complex than running it (inference). The training is conceptualized as a compression process of the internet. </span>
<span id="cb1-46"><a href="#cb1-46"></a></span>
<span id="cb1-47"><a href="#cb1-47"></a>The resources required for training Llama 2 70B: </span>
<span id="cb1-48"><a href="#cb1-48"></a></span>
<span id="cb1-49"><a href="#cb1-49"></a><span class="ss">- </span>roughly 10 terabytes of text from a crawl of the internet, </span>
<span id="cb1-50"><a href="#cb1-50"></a><span class="ss">- </span>processed by 6,000 GPUs over 12 days,</span>
<span id="cb1-51"><a href="#cb1-51"></a><span class="ss">- </span>at a cost of around $2 million. </span>
<span id="cb1-52"><a href="#cb1-52"></a></span>
<span id="cb1-53"><a href="#cb1-53"></a>This process compresses the massive text dataset into the 140GB parameters file, which he refers to as "*like a zip file of the internet*" with a compression ratio of approximately **100x**. Importantly, this is a *lossy* compression, meaning the model doesn't store an exact copy of the text, but a generalized representation, a kind of “Gestalt.” Karpathy points out that the numbers associated with Llama 2 70B, while significant, are “rookie numbers” compared to the training efforts for state-of-the-art models used in ChatGPT or Claude which are of magnitude 10x or more and costing tens or hundreds of millions of dollars.</span>
<span id="cb1-54"><a href="#cb1-54"></a></span>
<span id="cb1-55"><a href="#cb1-55"></a>After being *trained* (and *fine-tuned* - which is discussed later), running the LLM model which is neural network is faily computationally cheap. *So what is neural network is really doing?*</span>
<span id="cb1-56"><a href="#cb1-56"></a></span>
<span id="cb1-57"><a href="#cb1-57"></a><span class="fu">## LLM Dreams: Text Generation &amp; Hallucination</span></span>
<span id="cb1-58"><a href="#cb1-58"></a></span>
<span id="cb1-59"><a href="#cb1-59"></a>Fundamentally, a language model’s primary task during training is to predict the *next word* in a sequence. For example, from a sequence “Cat sat on a”, the neural network will predict what word comes next, e.g. “mat” with a 97% probability. Karpathy explains that this prediction task has a very close mathematical relationship to compression.  This simple prediction is a powerful objective, forcing the model to learn vast amounts of world knowledge. He uses a sample from Wikipedia about Ruth Handler to highlight how even seemingly mundane text is full of information that the model internalizes.</span>
<span id="cb1-60"><a href="#cb1-60"></a></span>
<span id="cb1-61"><a href="#cb1-61"></a>After training, running the model (inference) involves iterative text generation. The model predicts a word, feeds it back in, predicts the next, and so on, in a process Karpathy describes as “dreaming internet documents.” He shows examples of generated text resembling Java code, Amazon product listings, and Wikipedia articles. This generated text is often plausible but *hallucinated* – not necessarily true or derived directly from the training data. He gives examples of made up ISBNs and text referencing an obscure fish species, demonstrating that the model is not simply memorizing the training set.</span>
<span id="cb1-62"><a href="#cb1-62"></a></span>
<span id="cb1-63"><a href="#cb1-63"></a><span class="al">![All of these are dreamed by neural networks](1_network_dreams.png)</span></span>
<span id="cb1-64"><a href="#cb1-64"></a></span>
<span id="cb1-65"><a href="#cb1-65"></a><span class="fu">## How Do They Work? The Transformer Architecture</span></span>
<span id="cb1-66"><a href="#cb1-66"></a></span>
<span id="cb1-67"><a href="#cb1-67"></a>Into the inner workings of LLMs, they are based on a neural network architecture called the "*Transformer*". The full details of the mathematical operations and architecture are available. The challenge is that parameters are spread across the network and the exact nature of their interactions and contributions to the whole is unknown. While we know how to iteratively adjust the parameters to improve next-word prediction accuracy, we don't truly understand *how* these parameters collaborate to produce specific outputs. We do have some models suggesting they build up knowledge databases but this knowledge is imperfect and strange. Karpathy illustrates the weirdness of LLM knowledge using the viral "reversal course" example of Chat GPT's inability to recognize "Tom Cruise" as "Merily Feifer's son," showing the knowledge is one-dimensional and directionally dependent. He summarizes that LLMs should be viewed as “**mostly inscrutable artifacts**”, unlike engineered systems (like cars). He emphasizes that they are empirical artifacts that necessitate sophisticated evaluation methods.</span>
<span id="cb1-68"><a href="#cb1-68"></a></span>
<span id="cb1-69"><a href="#cb1-69"></a><span class="al">![Reversal Course](2_reversal_course.png)</span></span>
<span id="cb1-70"><a href="#cb1-70"></a></span>
<span id="cb1-71"><a href="#cb1-71"></a><span class="fu">## Fine-tuning into an Assistant: From Document Generators to Chatbots</span></span>
<span id="cb1-72"><a href="#cb1-72"></a></span>
<span id="cb1-73"><a href="#cb1-73"></a>The first training phase results in an internet document generator, which is not that helpful. The second major step is *fine-tuning*, the process of transforming this into a helpful “assistant model”. This transformation is achieved by switching from training on a large collection of internet text to training on a smaller, **carefully curated dataset of conversations**. </span>
<span id="cb1-74"><a href="#cb1-74"></a></span>
<span id="cb1-75"><a href="#cb1-75"></a>This dataset is typically created manually by human labelers who are provided with labeling instructions to generate questions and model answers. An example is provided of a question, with the correct assistant answer. The pre-training stage prioritizes data quantity but low quality, while the fine-tuning stage favors high-quality, carefully labelled Q&amp;A documents.  A dataset of 100,000 high-quality Q&amp;A documents would be more than sufficient for fine tuning. The fine tuning stage leverages the knowledge from pre-training and reconfigures the LLM to answer questions in a helpful manner. He gives the example of the prompt “can you help me with this code” with the corresponding helpful response. The model is able to “format” itself into an assistant that knows how to answer and responds to these kinds of questions, by learning patterns from the training data, and generating text word by word.</span>
<span id="cb1-76"><a href="#cb1-76"></a></span>
<span id="cb1-77"><a href="#cb1-77"></a><span class="fu">## Summary So Far: Pre-training vs. Fine-tuning</span></span>
<span id="cb1-78"><a href="#cb1-78"></a></span>
<span id="cb1-79"><a href="#cb1-79"></a>Karpathy summarizes the two-stage process:</span>
<span id="cb1-80"><a href="#cb1-80"></a><span class="ss">    *   </span>**Pre-training:** training on a massive internet dataset, resulting in a base model with world knowledge, this is computationally very expensive (millions of dollars) and done infrequently.</span>
<span id="cb1-81"><a href="#cb1-81"></a><span class="ss">    *   </span>**Fine-tuning:** training on high-quality Q&amp;A data, resulting in an assistant model, this is computationally cheaper and done more frequently (daily or weekly).</span>
<span id="cb1-82"><a href="#cb1-82"></a></span>
<span id="cb1-83"><a href="#cb1-83"></a>The Llama 2 series included both base and assistant models. The base model, without fine tuning, is not directly usable because it just samples documents rather than responding with an answer. Meta performed the pre-training and released the result. This allows others to do their own fine-tuning, providing tremendous freedom.</span>
<span id="cb1-84"><a href="#cb1-84"></a></span>
<span id="cb1-85"><a href="#cb1-85"></a><span class="al">![How to train your ~~dragon~~ ChatGPT](3_2stage.png)</span></span>
<span id="cb1-86"><a href="#cb1-86"></a></span>
<span id="cb1-87"><a href="#cb1-87"></a><span class="fu">## Appendix: Comparisons, Labeling Docs, RLHF, Synthetic Data, Leaderboard</span></span>
<span id="cb1-88"><a href="#cb1-88"></a></span>
<span id="cb1-89"><a href="#cb1-89"></a>This section expands on finer aspects of training and evaluation. Fine-tuning is followed by an *optional* third stage that leverages comparison labels. It is typically easier for a human labeler to rank options vs. generating the content.  The labelers are given example Haikus and they are asked to pick the best one. These comparisons are used to further fine-tune the model via Reinforcement Learning from Human Feedback (RLHF). Karpathy shows an example of labeling instructions from the InstructGPT paper asking labelers to be “helpful, truthful, and harmless”. He notes that these instructions can be tens or hundreds of pages long and very complicated.</span>
<span id="cb1-90"><a href="#cb1-90"></a></span>
<span id="cb1-91"><a href="#cb1-91"></a>He then explains that human labelers are used, although increasingly, machine assisted. Models can be used to sample answers and a human can do the cherry picking to improve efficiency. He then displays the Chatbot Arena leaderboard where Language Models are ranked according to their ELO ratings (just like chess). This ranking system determines which model does better on user queries. He observes the closed, proprietary models like those from OpenAI and Anthropic generally perform better. However, open-weights models (Llama series, Zephyr) are available and can be fine-tuned and used by everyone. The open-source models may be less accurate, but good enough for many applications.</span>
<span id="cb1-92"><a href="#cb1-92"></a></span>
<span id="cb1-93"><a href="#cb1-93"></a><span class="fu"># Part 2: Future of LLMs</span></span>
<span id="cb1-94"><a href="#cb1-94"></a></span>
<span id="cb1-95"><a href="#cb1-95"></a><span class="fu">## LLM Scaling Laws: The Path to Better Performance</span></span>
<span id="cb1-96"><a href="#cb1-96"></a></span>
<span id="cb1-97"><a href="#cb1-97"></a>Karpathy highlights the importance of *scaling laws*: the performance of LLMs in terms of next-word prediction accuracy is a predictable function of:</span>
<span id="cb1-98"><a href="#cb1-98"></a></span>
<span id="cb1-99"><a href="#cb1-99"></a><span class="ss">- </span>the number of parameters (N), and</span>
<span id="cb1-100"><a href="#cb1-100"></a><span class="ss">- </span>the amount of training data (D). </span>
<span id="cb1-101"><a href="#cb1-101"></a></span>
<span id="cb1-102"><a href="#cb1-102"></a>Increased parameters and increased dataset always result in better performance (predictability), so algorithmic progress is a bonus. It’s not necessarily needed for improvement, which creates a gold rush, because bigger and better clusters can provide better results. He emphasizes this is correlated with performance across many downstream tasks.</span>
<span id="cb1-103"><a href="#cb1-103"></a></span>
<span id="cb1-104"><a href="#cb1-104"></a><span class="al">![Free scaling!](4_free_scaling.png)</span></span>
<span id="cb1-105"><a href="#cb1-105"></a></span>
<span id="cb1-106"><a href="#cb1-106"></a><span class="fu">## Tool Use: Expanding Capabilities</span></span>
<span id="cb1-107"><a href="#cb1-107"></a></span>
<span id="cb1-108"><a href="#cb1-108"></a>He uses a concrete example to demonstrate the *tool use* capabilities of LLMs using ChatGPT, by providing a query to find information on Scale AI’s funding rounds. ChatGPT can browse the internet using *search tools*, it then takes the information from search results, and uses that to answer the prompt. The model then can use a *calculator tool* to perform arithmetic tasks, and generates an estimation based on ratios from data it previously received. It can then use a *python interpreter* with the matplotlib library to generate graphs and visualizations to the data. This allows the language model to solve problems just as humans might, using external tools to aid in problem solving.  It can also use *DALL-E* for image generation. The LLM orchestrates the various tools to solve the prompt and return the result to the user.</span>
<span id="cb1-109"><a href="#cb1-109"></a></span>
<span id="cb1-110"><a href="#cb1-110"></a><span class="fu">## Multimodality: Beyond Text</span></span>
<span id="cb1-111"><a href="#cb1-111"></a></span>
<span id="cb1-112"><a href="#cb1-112"></a>The next major aspect is *multimodality*, showing how LLMs can interact beyond text with images, audio, etc.  Karpathy gives the example of ChatGPT analyzing a hand-sketched website diagram, generating functional HTML and JavaScript. ChatGPT can also hear and speak and thus enable speech-to-speech interactions.</span>
<span id="cb1-113"><a href="#cb1-113"></a></span>
<span id="cb1-114"><a href="#cb1-114"></a><span class="al">![Multimodality](5_multimodality.png)</span></span>
<span id="cb1-115"><a href="#cb1-115"></a></span>
<span id="cb1-116"><a href="#cb1-116"></a><span class="fu">## Thinking, System 1/2: Reasoning and Planning</span></span>
<span id="cb1-117"><a href="#cb1-117"></a></span>
<span id="cb1-118"><a href="#cb1-118"></a>Karpathy introduces the concept of *System 1* and *System 2* thinking, inspired by Daniel Kahneman's work. System 1 is fast, instinctive thinking (*the answer is cached already*), whereas System 2 is slower, more deliberate reasoning.</span>
<span id="cb1-119"><a href="#cb1-119"></a></span>
<span id="cb1-120"><a href="#cb1-120"></a><span class="al">![2 systems of thinking](6_2_sytems.png)</span></span>
<span id="cb1-121"><a href="#cb1-121"></a></span>
<span id="cb1-122"><a href="#cb1-122"></a>LLMs currently only operate in System 1 mode, sampling word by word without deep planning. A major future direction is to enable *System 2* thinking, where models can spend more time to improve quality. The idea is to make a trade off between compute time and accuracy. Karpathy notes how this is not possible today, where the LLM just goes *chunk chunk chunk x3.14* and sampling words in the sequence without “thinking” through it. He emphasizes the importance of converting time into accuracy using tree-of-thought and other techniques.</span>
<span id="cb1-123"><a href="#cb1-123"></a></span>
<span id="cb1-124"><a href="#cb1-124"></a><span class="al">![Towarding the Tree of Thoughts](7_ToT.png)</span></span>
<span id="cb1-125"><a href="#cb1-125"></a></span>
<span id="cb1-126"><a href="#cb1-126"></a><span class="fu">## Self-improvement: Going Beyond Human Limits</span></span>
<span id="cb1-127"><a href="#cb1-127"></a></span>
<span id="cb1-128"><a href="#cb1-128"></a>He references DeepMind's AlphaGo, which initially learned by imitating human players but later surpassed human performance through self-improvement.  Karpathy argues that current LLMs are only in the **imitation** stage, and the next challenge is to achieve *self-improvement* for them, similar to the AlphaGo step two. The lack of a **general reward function**, unlike the win/loss criteria of the go game, is the main challenge. In narrow domains though, this may be achievable.</span>
<span id="cb1-129"><a href="#cb1-129"></a></span>
<span id="cb1-130"><a href="#cb1-130"></a><span class="al">![Self-improvement is key for AlphaGo to surpass the best human in 40 days](8_alpha_go.png)</span></span>
<span id="cb1-131"><a href="#cb1-131"></a></span>
<span id="cb1-132"><a href="#cb1-132"></a><span class="fu">## LLM Customization: Expert Systems</span></span>
<span id="cb1-133"><a href="#cb1-133"></a></span>
<span id="cb1-134"><a href="#cb1-134"></a>Karpathy explains the need for customization to allow LLMs to become specialized in specific tasks. This is especially important due to the diversity of needs in the real world. He provides the example of the GPT Store by OpenAI, which allows users to create custom GPTs using custom instructions, and **retrieval augmented generation**. Fine-tuning LLMs may be needed to have experts in specific areas.</span>
<span id="cb1-135"><a href="#cb1-135"></a></span>
<span id="cb1-136"><a href="#cb1-136"></a>This is what people are hyped doing nowaday 😪.</span>
<span id="cb1-137"><a href="#cb1-137"></a></span>
<span id="cb1-138"><a href="#cb1-138"></a><span class="fu">## LLM OS: A New Paradigm</span></span>
<span id="cb1-139"><a href="#cb1-139"></a></span>
<span id="cb1-140"><a href="#cb1-140"></a>Karpathy proposes that LLMs should not be seen as mere chatbots, but rather the *kernel process of an emerging operating system*.  He explains that the LLM is coordinating a lot of resources for problem solving, acting like the kernel of an operating system. He then goes to show an analog of a computer’s components, and what they might correspond to in LLM space. He outlines the LLM OS’s capabilities, such as internet browsing, local file referencing, access to software tools, ability to generate/interpret images, videos, and audio, long-term “thinking”, customization, and self-improvement. This maps directly to what we expect an operating system to do. He makes an analogy to a computer’s memory hierarchy with hard disks (internet/local files), random access memory (context window). He also draws a parallel between the diverse OS landscape of today with the proprietary desktop OS like Windows and MacOS vs open-source alternatives. In the LLM space, similarly there’s GPT/Claude/Bard and the open-source landscape built around Llama.</span>
<span id="cb1-141"><a href="#cb1-141"></a></span>
<span id="cb1-142"><a href="#cb1-142"></a><span class="al">![Embed the LLMs into the kernel](9_llm_os.png)</span></span>
<span id="cb1-143"><a href="#cb1-143"></a></span>
<span id="cb1-144"><a href="#cb1-144"></a><span class="fu"># Part 3: LLM Security</span></span>
<span id="cb1-145"><a href="#cb1-145"></a></span>
<span id="cb1-146"><a href="#cb1-146"></a><span class="fu">## LLM Security Intro: The New Battleground</span></span>
<span id="cb1-147"><a href="#cb1-147"></a></span>
<span id="cb1-148"><a href="#cb1-148"></a>Karpathy then switches gears to security challenges, arguing that the new paradigm of LLMs introduce new security vulnerabilities. He emphasizes that cat and mouse security game that we are familiar with in computer security also exists in LLM security.</span>
<span id="cb1-149"><a href="#cb1-149"></a></span>
<span id="cb1-150"><a href="#cb1-150"></a><span class="fu">## Jailbreaks: Bypassing Safety Restrictions</span></span>
<span id="cb1-151"><a href="#cb1-151"></a></span>
<span id="cb1-152"><a href="#cb1-152"></a>He starts with *jailbreak attacks*, demonstrating how prompts can circumvent safety restrictions and elicit harmful information from LLMs. One example given is the grandmother-role-play where the LLM was tricked to give instructions on how to make Napalm. There are many ways to trick a system into providing unsafe responses. He gives the example of base64 encoding a dangerous request to elicit unsafe information because training for safety often focuses on English text. The universal transferable suffix is another attack vector: adding the suffix will bypass safety filters. Image noise based jailbreaks are also possible by carefully crafting the noise pattern.</span>
<span id="cb1-153"><a href="#cb1-153"></a></span>
<span id="cb1-154"><a href="#cb1-154"></a><span class="fu">## Prompt Injection: Hijacking the Model</span></span>
<span id="cb1-155"><a href="#cb1-155"></a></span>
<span id="cb1-156"><a href="#cb1-156"></a>Karpathy moves to *prompt injection attacks*, where hidden or injected prompts hijack the model, causing it to follow undesirable instructions. One example is using faint text hidden in an image, containing a prompt injection, to make ChatGPT talk about Sephora sales. He explains that prompt injection can exist in web pages. This is demonstrated using the scenario of searching for movies in Bing and having Bing inject a fraud link due to a web page the search accessed having a prompt injection vulnerability. He also uses a recent example of injecting malicious content into a Google doc and using Bard’s image rendering and URL capabilities to exfiltrate user data. He explains that while engineers implement mitigations, determined attackers always find a loophole (Google Apps scripts).</span>
<span id="cb1-157"><a href="#cb1-157"></a></span>
<span id="cb1-158"><a href="#cb1-158"></a><span class="fu">## Data Poisoning: The Backdoor Threat</span></span>
<span id="cb1-159"><a href="#cb1-159"></a></span>
<span id="cb1-160"><a href="#cb1-160"></a>The final attack vector is *data poisoning* or *backdoor attacks*. He discusses how a trigger phrase can cause the model to behave maliciously when the text is present. He discusses the James Bond trigger phrase that is injected during fine tuning. The trigger phrase can cause any task to become non-sensical, or to incorrectly classify threats in a security application. While the example was shown to work for fine-tuning, Karpathy explains that the idea can extend to pre-training.</span>
<span id="cb1-161"><a href="#cb1-161"></a></span>
<span id="cb1-162"><a href="#cb1-162"></a><span class="fu">## LLM Security Conclusions: A Constant Battle</span></span>
<span id="cb1-163"><a href="#cb1-163"></a></span>
<span id="cb1-164"><a href="#cb1-164"></a>Karpathy summarizes that while defenses exist, the security landscape in LLMs will likely be a constant "cat and mouse game," mirroring traditional computer security. He points out that all the attacks have defenses, but they can be bypassed and repatched and so on. The field is very new and actively evolving.</span>
<span id="cb1-165"><a href="#cb1-165"></a></span>
<span id="cb1-166"><a href="#cb1-166"></a><span class="fu">## Outro</span></span>
<span id="cb1-167"><a href="#cb1-167"></a></span>
<span id="cb1-168"><a href="#cb1-168"></a>Karpathy ends the talk by summarizing all major aspects he touched upon. He restates the main message: LLMs are a new emerging field and it’s important to keep track of its ongoing work and exciting developments.</span>
<span id="cb1-169"><a href="#cb1-169"></a></span>
<span id="cb1-170"><a href="#cb1-170"></a><span class="fu"># resources</span></span>
<span id="cb1-171"><a href="#cb1-171"></a></span>
<span id="cb1-172"><a href="#cb1-172"></a><span class="ss">1. </span>video: <span class="ot">&lt;https://www.youtube.com/watch?v=zjkBMFhNj_g&gt;</span>;</span>
<span id="cb1-173"><a href="#cb1-173"></a><span class="ss">2. </span>pdf slide: <span class="ot">&lt;https://drive.google.com/file/d/1pxx_ZI7O-Nwl7ZLNk5hI3WzAsTLwvNU7/view&gt;</span></span>
<span id="cb1-174"><a href="#cb1-174"></a><span class="ss">3. </span>a recommended to read blog post: <span class="ot">&lt;https://karpathy.github.io/2015/05/21/rnn-effectiveness/&gt;</span></span>
<span id="cb1-175"><a href="#cb1-175"></a><span class="ss">4. </span>a <span class="in">`run.c`</span> file: <span class="ot">&lt;https://github.com/karpathy/llama2.c/blob/master/run.c&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block"><a href="https://creativecommons.org/licenses/by-nc-nd/4.0/"><i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i></a> 2023-2024 Le Khac Tuan</span></p>
</div>   
    <div class="nav-footer-center">
<p><span class="faux-block"> Designed with <i class="fa-solid fa-heart" aria-label="heart"></i>, <span id="commit-info">Loading last commit…</span> </span></p>
</div>
    <div class="nav-footer-right">
<p><span class="faux-block">Made with <a href="https://quarto.org/">Quarto</a></span></p>
</div>
  </div>
</footer>
<script type="application/javascript" src="commit_info.js"></script>




</body></html>